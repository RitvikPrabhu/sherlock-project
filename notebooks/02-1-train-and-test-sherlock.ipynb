{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook enables training and testing of Sherlock.\n",
    "The procedure is:\n",
    "- Load train, val, test datasets (should be preprocessed)\n",
    "- Initialize model using the \"pretrained\" model or by training one from scratch.\n",
    "- Evaluate and analyse the model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTHONHASHSEED=13\n"
     ]
    }
   ],
   "source": [
    "%env PYTHONHASHSEED=13\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will be the ID for the retrained model,\n",
    "#further down predictions can also be made with the original model: \"sherlock\"\n",
    "model_id = 'retrained_sherlock'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "from sherlock.deploy.model import SherlockModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets for training, validation, testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2022-09-25 11:23:31.034071\n",
      "Load data (train) process took 0:00:00.861180 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "print(f'Started at {start}')\n",
    "\n",
    "X_train = pd.read_parquet('../data/data/processed/train.parquet')\n",
    "y_train = pd.read_parquet('../data/data/raw/train_labels.parquet').values.flatten()\n",
    "\n",
    "y_train = np.array([x.lower() for x in y_train])\n",
    "\n",
    "print(f'Load data (train) process took {datetime.now() - start} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct types for columns in the Dataframe (should be all float32):\n",
      "{dtype('float32')}\n"
     ]
    }
   ],
   "source": [
    "print('Distinct types for columns in the Dataframe (should be all float32):')\n",
    "print(set(X_train.dtypes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2022-09-25 11:23:32.215566\n",
      "Load data (validation) process took 0:00:00.540727 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "print(f'Started at {start}')\n",
    "\n",
    "X_validation = pd.read_parquet('../data/data/processed/validation.parquet')\n",
    "y_validation = pd.read_parquet('../data/data/raw/val_labels.parquet').values.flatten()\n",
    "\n",
    "y_validation = np.array([x.lower() for x in y_validation])\n",
    "\n",
    "print(f'Load data (validation) process took {datetime.now() - start} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2022-09-25 11:23:32.869818\n",
      "Finished at 2022-09-25 11:23:33.412601, took 0:00:00.542802 seconds\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "print(f'Started at {start}')\n",
    "\n",
    "X_test = pd.read_parquet('../data/data/processed/test.parquet')\n",
    "y_test = pd.read_parquet('../data/data/raw/test_labels.parquet').values.flatten()\n",
    "\n",
    "y_test = np.array([x.lower() for x in y_test])\n",
    "\n",
    "print(f'Finished at {datetime.now()}, took {datetime.now() - start} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the model\n",
    "Two options:\n",
    "- Load Sherlock model with pretrained weights\n",
    "- Fit Sherlock model from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: load Sherlock with pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# start = datetime.now()\n",
    "# print(f'Started at {start}')\n",
    "\n",
    "# model = SherlockModel();\n",
    "# model.initialize_model_from_json(with_weights=True, model_id=\"sherlock\");\n",
    "\n",
    "# print('Initialized model.')\n",
    "# print(f'Finished at {datetime.now()}, took {datetime.now() - start} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: fit Sherlock from scratch (and save for later use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"retrained_sherlock\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2022-09-25 11:23:33.669550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 11:23:34.301137: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-25 11:23:34.309753: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "/home/ritvikp/.conda/envs/sherlock/lib/python3.8/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0925 11:23:35.088444 46912496407488 ag_logging.py:142] AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x2aabb39cd790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x2aabb39cd790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "254/254 [==============================] - ETA: 0s - loss: 2.0204 - categorical_accuracy: 0.5743"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0925 11:37:12.239740 46912496407488 ag_logging.py:142] AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x2aadb0b3ea60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x2aadb0b3ea60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "254/254 [==============================] - 1116s 4s/step - loss: 2.0204 - categorical_accuracy: 0.5743 - val_loss: 1.3472 - val_categorical_accuracy: 0.7550\n",
      "Epoch 2/10\n",
      "254/254 [==============================] - 1107s 4s/step - loss: 1.1517 - categorical_accuracy: 0.7763 - val_loss: 0.8903 - val_categorical_accuracy: 0.8457\n",
      "Epoch 3/10\n",
      "254/254 [==============================] - 1102s 4s/step - loss: 0.9819 - categorical_accuracy: 0.8179 - val_loss: 0.7978 - val_categorical_accuracy: 0.8674\n",
      "Epoch 4/10\n",
      "254/254 [==============================] - 1129s 4s/step - loss: 0.9021 - categorical_accuracy: 0.8374 - val_loss: 0.7490 - val_categorical_accuracy: 0.8768\n",
      "Epoch 5/10\n",
      "254/254 [==============================] - 1099s 4s/step - loss: 0.8485 - categorical_accuracy: 0.8509 - val_loss: 0.7105 - val_categorical_accuracy: 0.8852\n",
      "Epoch 6/10\n",
      "254/254 [==============================] - 1117s 4s/step - loss: 0.8058 - categorical_accuracy: 0.8617 - val_loss: 0.6823 - val_categorical_accuracy: 0.8921\n",
      "Epoch 7/10\n",
      "254/254 [==============================] - 1239s 5s/step - loss: 0.7750 - categorical_accuracy: 0.8687 - val_loss: 0.6524 - val_categorical_accuracy: 0.9005\n",
      "Epoch 8/10\n",
      "254/254 [==============================] - 1128s 4s/step - loss: 0.7465 - categorical_accuracy: 0.8758 - val_loss: 0.6292 - val_categorical_accuracy: 0.9049\n",
      "Epoch 9/10\n",
      "254/254 [==============================] - 1221s 5s/step - loss: 0.7236 - categorical_accuracy: 0.8801 - val_loss: 0.6122 - val_categorical_accuracy: 0.9085\n",
      "Epoch 10/10\n",
      "254/254 [==============================] - 1176s 5s/step - loss: 0.7021 - categorical_accuracy: 0.8846 - val_loss: 0.5906 - val_categorical_accuracy: 0.9155\n",
      "Trained and saved new model.\n",
      "Finished at 2022-09-25 14:34:08.089110, took 3:10:34.419588 seconds\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "print(f'Started at {start}')\n",
    "\n",
    "model = SherlockModel()\n",
    "# Model will be stored with ID `model_id`\n",
    "model.fit(X_train, y_train, X_validation, y_validation, model_id=model_id)\n",
    "\n",
    "print('Trained and saved new model.')\n",
    "print(f'Finished at {datetime.now()}, took {datetime.now() - start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.store_weights(model_id=model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0925 14:36:54.734713 46912496407488 ag_logging.py:142] AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x2aabb8b72af0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x2aabb8b72af0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = model.predict(X_test, model_id)\n",
    "predicted_labels = np.array([x.lower() for x in predicted_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction count 65007, type = <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.914404689647462"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'prediction count {len(predicted_labels)}, type = {type(predicted_labels)}')\n",
    "\n",
    "size=len(y_test)\n",
    "\n",
    "# Should be fully deterministic too.\n",
    "f1_score(y_test[:size], predicted_labels[:size], average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using the original model, model_id should be replaced with \"sherlock\"\n",
    "#model_id = \"sherlock\"\n",
    "classes = np.load(f\"../model_files/classes_{model_id}.npy\", allow_pickle=True)\n",
    "\n",
    "report = classification_report(y_test, predicted_labels, output_dict=True)\n",
    "\n",
    "class_scores = list(filter(lambda x: isinstance(x, tuple) and isinstance(x[1], dict) and 'f1-score' in x[1] and x[0] in classes, list(report.items())))\n",
    "\n",
    "class_scores = sorted(class_scores, key=lambda item: item[1]['f1-score'], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 5 Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tf1-score\tprecision\trecall\t\tsupport\n",
      "industry\t0.987\t\t0.987\t\t0.986\t\t2958\n",
      "birth date\t0.979\t\t0.975\t\t0.983\t\t479\n",
      "sex\t\t0.971\t\t0.978\t\t0.965\t\t2997\n",
      "symbol\t\t0.968\t\t0.960\t\t0.975\t\t1752\n",
      "year\t\t0.964\t\t0.979\t\t0.949\t\t3015\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\t\\tf1-score\\tprecision\\trecall\\t\\tsupport\")\n",
    "\n",
    "for key, value in class_scores[0:5]:\n",
    "    if len(key) >= 8:\n",
    "        tabs = '\\t' * 1\n",
    "    else:\n",
    "        tabs = '\\t' * 2\n",
    "\n",
    "    print(f\"{key}{tabs}{value['f1-score']:.3f}\\t\\t{value['precision']:.3f}\\t\\t{value['recall']:.3f}\\t\\t{value['support']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bottom 5 Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tf1-score\tprecision\trecall\t\tsupport\n",
      "range\t\t0.803\t\t0.906\t\t0.721\t\t577\n",
      "nationality\t0.769\t\t0.838\t\t0.710\t\t424\n",
      "rank\t\t0.765\t\t0.723\t\t0.813\t\t2983\n",
      "person\t\t0.705\t\t0.908\t\t0.577\t\t579\n",
      "sales\t\t0.411\t\t0.776\t\t0.280\t\t322\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\t\\tf1-score\\tprecision\\trecall\\t\\tsupport\")\n",
    "\n",
    "for key, value in class_scores[len(class_scores)-5:len(class_scores)]:\n",
    "    if len(key) >= 8:\n",
    "        tabs = '\\t' * 1\n",
    "    else:\n",
    "        tabs = '\\t' * 2\n",
    "\n",
    "    print(f\"{key}{tabs}{value['f1-score']:.3f}\\t\\t{value['precision']:.3f}\\t\\t{value['recall']:.3f}\\t\\t{value['support']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     address      0.954     0.965     0.959      3003\n",
      "         age      0.882     0.967     0.922      3033\n",
      "        area      0.927     0.824     0.872      1987\n",
      "  birth date      0.975     0.983     0.979       479\n",
      " birth place      0.992     0.928     0.959       418\n",
      "       brand      0.891     0.737     0.806       574\n",
      "        city      0.881     0.935     0.907      2966\n",
      "   continent      0.885     0.885     0.885       227\n",
      "     country      0.912     0.961     0.936      3038\n",
      "      county      0.955     0.955     0.955      2959\n",
      "    currency      0.972     0.953     0.963       405\n",
      "         day      0.930     0.888     0.909      3038\n",
      "    duration      0.944     0.947     0.946      3000\n",
      "    industry      0.987     0.986     0.987      2958\n",
      "    language      0.870     0.966     0.916      1474\n",
      "    location      0.936     0.835     0.883      2949\n",
      "manufacturer      0.878     0.920     0.898       945\n",
      "        name      0.864     0.911     0.887      3017\n",
      " nationality      0.838     0.710     0.769       424\n",
      "       order      0.813     0.912     0.860      1462\n",
      "      person      0.908     0.577     0.705       579\n",
      "     product      0.905     0.946     0.925      2647\n",
      "       range      0.906     0.721     0.803       577\n",
      "        rank      0.723     0.813     0.765      2983\n",
      "      region      0.904     0.817     0.858      2740\n",
      "       sales      0.776     0.280     0.411       322\n",
      "         sex      0.978     0.965     0.971      2997\n",
      "       state      0.955     0.956     0.956      3030\n",
      "      status      0.953     0.962     0.958      3100\n",
      "      symbol      0.960     0.975     0.968      1752\n",
      "        type      0.928     0.933     0.931      2909\n",
      "        year      0.979     0.949     0.964      3015\n",
      "\n",
      "    accuracy                          0.916     65007\n",
      "   macro avg      0.911     0.877     0.888     65007\n",
      "weighted avg      0.917     0.916     0.914     65007\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predicted_labels, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1187] expected \"address\" but predicted \"day\"\n",
      "[1201] expected \"address\" but predicted \"city\"\n",
      "[1585] expected \"address\" but predicted \"city\"\n",
      "[2256] expected \"address\" but predicted \"name\"\n",
      "[2303] expected \"address\" but predicted \"area\"\n",
      "[2393] expected \"address\" but predicted \"location\"\n",
      "[3218] expected \"address\" but predicted \"location\"\n",
      "[4640] expected \"address\" but predicted \"city\"\n",
      "[4787] expected \"address\" but predicted \"duration\"\n",
      "[5261] expected \"address\" but predicted \"city\"\n",
      "[5685] expected \"address\" but predicted \"city\"\n",
      "[5729] expected \"address\" but predicted \"location\"\n",
      "[6327] expected \"address\" but predicted \"manufacturer\"\n",
      "[7404] expected \"address\" but predicted \"city\"\n",
      "[9532] expected \"address\" but predicted \"manufacturer\"\n",
      "[9920] expected \"address\" but predicted \"language\"\n",
      "[10188] expected \"address\" but predicted \"product\"\n",
      "[11837] expected \"address\" but predicted \"day\"\n",
      "[12608] expected \"address\" but predicted \"rank\"\n",
      "[12829] expected \"address\" but predicted \"name\"\n",
      "[14477] expected \"address\" but predicted \"language\"\n",
      "[15145] expected \"address\" but predicted \"language\"\n",
      "[15481] expected \"address\" but predicted \"city\"\n",
      "[15525] expected \"address\" but predicted \"city\"\n",
      "[16143] expected \"address\" but predicted \"name\"\n",
      "[16481] expected \"address\" but predicted \"location\"\n",
      "[16821] expected \"address\" but predicted \"location\"\n",
      "[17047] expected \"address\" but predicted \"language\"\n",
      "[17088] expected \"address\" but predicted \"city\"\n",
      "[17689] expected \"address\" but predicted \"language\"\n",
      "[17788] expected \"address\" but predicted \"language\"\n",
      "[19063] expected \"address\" but predicted \"language\"\n",
      "[19185] expected \"address\" but predicted \"country\"\n",
      "[21290] expected \"address\" but predicted \"area\"\n",
      "[22018] expected \"address\" but predicted \"location\"\n",
      "[22419] expected \"address\" but predicted \"language\"\n",
      "[22532] expected \"address\" but predicted \"location\"\n",
      "[22631] expected \"address\" but predicted \"city\"\n",
      "[22678] expected \"address\" but predicted \"type\"\n",
      "[22787] expected \"address\" but predicted \"location\"\n",
      "[22911] expected \"address\" but predicted \"name\"\n",
      "[23055] expected \"address\" but predicted \"location\"\n",
      "[24509] expected \"address\" but predicted \"location\"\n",
      "[24818] expected \"address\" but predicted \"location\"\n",
      "[25623] expected \"address\" but predicted \"area\"\n",
      "[25742] expected \"address\" but predicted \"area\"\n",
      "[25753] expected \"address\" but predicted \"location\"\n",
      "[26579] expected \"address\" but predicted \"product\"\n",
      "[26608] expected \"address\" but predicted \"name\"\n",
      "[28218] expected \"address\" but predicted \"name\"\n",
      "[28573] expected \"address\" but predicted \"language\"\n",
      "[28663] expected \"address\" but predicted \"year\"\n",
      "[28668] expected \"address\" but predicted \"location\"\n",
      "[28732] expected \"address\" but predicted \"name\"\n",
      "[29339] expected \"address\" but predicted \"language\"\n",
      "[29636] expected \"address\" but predicted \"location\"\n",
      "[30714] expected \"address\" but predicted \"name\"\n",
      "[31830] expected \"address\" but predicted \"area\"\n",
      "[33071] expected \"address\" but predicted \"symbol\"\n",
      "[33755] expected \"address\" but predicted \"location\"\n",
      "[34929] expected \"address\" but predicted \"duration\"\n",
      "[35994] expected \"address\" but predicted \"order\"\n",
      "[36306] expected \"address\" but predicted \"language\"\n",
      "[36869] expected \"address\" but predicted \"city\"\n",
      "[38517] expected \"address\" but predicted \"location\"\n",
      "[39210] expected \"address\" but predicted \"symbol\"\n",
      "[40324] expected \"address\" but predicted \"location\"\n",
      "[40391] expected \"address\" but predicted \"product\"\n",
      "[40584] expected \"address\" but predicted \"language\"\n",
      "[40677] expected \"address\" but predicted \"language\"\n",
      "[41137] expected \"address\" but predicted \"rank\"\n",
      "[41181] expected \"address\" but predicted \"product\"\n",
      "[41350] expected \"address\" but predicted \"product\"\n",
      "[41889] expected \"address\" but predicted \"day\"\n",
      "[42634] expected \"address\" but predicted \"name\"\n",
      "[42825] expected \"address\" but predicted \"location\"\n",
      "[42880] expected \"address\" but predicted \"city\"\n",
      "[43719] expected \"address\" but predicted \"location\"\n",
      "[44269] expected \"address\" but predicted \"country\"\n",
      "[45617] expected \"address\" but predicted \"location\"\n",
      "[45745] expected \"address\" but predicted \"product\"\n",
      "[46897] expected \"address\" but predicted \"status\"\n",
      "[46985] expected \"address\" but predicted \"location\"\n",
      "[47727] expected \"address\" but predicted \"symbol\"\n",
      "[48192] expected \"address\" but predicted \"status\"\n",
      "[48830] expected \"address\" but predicted \"language\"\n",
      "[49073] expected \"address\" but predicted \"location\"\n",
      "[51399] expected \"address\" but predicted \"region\"\n",
      "[52603] expected \"address\" but predicted \"name\"\n",
      "[52782] expected \"address\" but predicted \"city\"\n",
      "[54105] expected \"address\" but predicted \"day\"\n",
      "[54164] expected \"address\" but predicted \"location\"\n",
      "[54767] expected \"address\" but predicted \"range\"\n",
      "[55162] expected \"address\" but predicted \"county\"\n",
      "[56111] expected \"address\" but predicted \"language\"\n",
      "[57986] expected \"address\" but predicted \"language\"\n",
      "[59662] expected \"address\" but predicted \"name\"\n",
      "[59806] expected \"address\" but predicted \"area\"\n",
      "[60279] expected \"address\" but predicted \"product\"\n",
      "[60420] expected \"address\" but predicted \"duration\"\n",
      "[61914] expected \"address\" but predicted \"duration\"\n",
      "[62998] expected \"address\" but predicted \"location\"\n",
      "[64401] expected \"address\" but predicted \"area\"\n",
      "[64711] expected \"address\" but predicted \"status\"\n",
      "[64864] expected \"address\" but predicted \"location\"\n",
      "Total mismatches: 5490 (F1 score: 0.914404689647462)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('rank', 559),\n",
       " ('region', 502),\n",
       " ('location', 487),\n",
       " ('area', 350),\n",
       " ('day', 339),\n",
       " ('name', 269),\n",
       " ('person', 245),\n",
       " ('sales', 232),\n",
       " ('type', 194),\n",
       " ('city', 193),\n",
       " ('range', 161),\n",
       " ('duration', 158),\n",
       " ('year', 154),\n",
       " ('brand', 151),\n",
       " ('product', 144),\n",
       " ('county', 133),\n",
       " ('state', 132),\n",
       " ('order', 128),\n",
       " ('nationality', 123),\n",
       " ('country', 119),\n",
       " ('status', 117),\n",
       " ('address', 105),\n",
       " ('sex', 104),\n",
       " ('age', 99),\n",
       " ('manufacturer', 76),\n",
       " ('language', 50),\n",
       " ('symbol', 43),\n",
       " ('industry', 40),\n",
       " ('birth place', 30),\n",
       " ('continent', 26),\n",
       " ('currency', 19),\n",
       " ('birth date', 8)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = len(y_test)\n",
    "mismatches = list()\n",
    "\n",
    "for idx, k1 in enumerate(y_test[:size]):\n",
    "    k2 = predicted_labels[idx]\n",
    "\n",
    "    if k1 != k2:\n",
    "        mismatches.append(k1)\n",
    "        \n",
    "        # zoom in to specific errors. Use the index in the next step\n",
    "        if k1 in ('address'):\n",
    "            print(f'[{idx}] expected \"{k1}\" but predicted \"{k2}\"')\n",
    "        \n",
    "f1 = f1_score(y_test[:size], predicted_labels[:size], average=\"weighted\")\n",
    "print(f'Total mismatches: {len(mismatches)} (F1 score: {f1})')\n",
    "\n",
    "data = Counter(mismatches)\n",
    "data.most_common()   # Returns all unique items and their counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = pd.read_parquet('../data/data/raw/test_values.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted \"duration\", actual label \"duration\". Actual values:\n",
      "[['5-15 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', '5-15 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', '5-15 minutes', 'less than 5 minutes', 'less than 5 minutes', '5-15 minutes', '5-15 minutes', '5-15 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', '5-15 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', '16-30 minutes', 'less than 5 minutes', '16-30 minutes', 'less than 5 minutes', '5-15 minutes', 'less than 5 minutes', '5-15 minutes', '5-15 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', '5-15 minutes', 'less than 5 minutes', '5-15 minutes', 'less than 5 minutes', '5-15 minutes', 'less than 5 minutes', '5-15 minutes', '5-15 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', '5-15 minutes', 'less than 5 minutes', '5-15 minutes', 'less than 5 minutes', '5-15 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', '5-15 minutes', '5-15 minutes', '5-15 minutes', '5-15 minutes', '5-15 minutes', 'less than 5 minutes', '5-15 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', '5-15 minutes', '5-15 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', '5-15 minutes', '5-15 minutes', 'less than 5 minutes', 'less than 5 minutes', '5-15 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', '5-15 minutes', '5-15 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', '5-15 minutes', 'less than 5 minutes', '16-30 minutes', '5-15 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', '5-15 minutes', '5-15 minutes', 'less than 5 minutes', '5-15 minutes', 'less than 5 minutes', '5-15 minutes', 'less than 5 minutes', '5-15 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', '5-15 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', '5-15 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', '5-15 minutes', 'less than 5 minutes', '5-15 minutes', 'less than 5 minutes', 'less than 5 minutes', '5-15 minutes', 'less than 5 minutes', '16-30 minutes', 'less than 5 minutes', 'less than 5 minutes', '5-15 minutes', '5-15 minutes', '5-15 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', '5-15 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', '5-15 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', '5-15 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', '31- 59 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', '5-15 minutes', 'less than 5 minutes', '5-15 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', '5-15 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', '5-15 minutes', '5-15 minutes', '5-15 minutes', '5-15 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', '5-15 minutes', '16-30 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes', '5-15 minutes', '5-15 minutes', 'less than 5 minutes', '5-15 minutes', 'less than 5 minutes', 'less than 5 minutes', 'less than 5 minutes']]\n"
     ]
    }
   ],
   "source": [
    "idx = 200\n",
    "original = test_samples.iloc[idx]\n",
    "converted = original.apply(literal_eval).to_list()\n",
    "\n",
    "print(f'Predicted \"{predicted_labels[idx]}\", actual label \"{y_test[idx]}\". Actual values:\\n{converted}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('sherlock')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "dbbef01d25d9fb4d9430fa9d81ea780e18a1c669119e240c1440cbb3ef3d3f19"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
