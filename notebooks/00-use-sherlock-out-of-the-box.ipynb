{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fde5449",
   "metadata": {},
   "source": [
    "# Using Sherlock out-of-the-box\n",
    "This notebook shows how to predict a semantic type for a given table column.\n",
    "The steps are basically:\n",
    "- Download files for word embedding and paragraph vector feature extraction (downloads only once) and initialize feature extraction models.\n",
    "- Extract features from table columns.\n",
    "- Initialize Sherlock.\n",
    "- Make a prediction for the feature representation of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86c1bf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "from sherlock import helpers\n",
    "from sherlock.deploy.model import SherlockModel\n",
    "from sherlock.functional import extract_features_to_csv\n",
    "from sherlock.features.paragraph_vectors import initialise_pretrained_model, initialise_nltk\n",
    "from sherlock.features.preprocessing import (\n",
    "    extract_features,\n",
    "    convert_string_lists_to_lists,\n",
    "    prepare_feature_extraction,\n",
    "    load_parquet_values,\n",
    ")\n",
    "from sherlock.features.word_embeddings import initialise_word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9530d108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTHONHASHSEED=13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'13'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%env PYTHONHASHSEED=13\n",
    "%env PYTHONHASHSEED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498b3b1d",
   "metadata": {},
   "source": [
    "## Initialize feature extraction models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "959e2437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing feature extraction by downloading 4 files:\n",
      "        \n",
      " ../sherlock/features/glove.6B.50d.txt, \n",
      " ../sherlock/features/par_vec_trained_400.pkl.docvecs.vectors_docs.npy,\n",
      "        \n",
      " ../sherlock/features/par_vec_trained_400.pkl.trainables.syn1neg.npy, and \n",
      " ../sherlock/features/par_vec_trained_400.pkl.wv.vectors.npy.\n",
      "        \n",
      "All files for extracting word and paragraph embeddings are present.\n",
      "Initialising word embeddings\n",
      "Initialise Word Embeddings process took 0:00:05.219903 seconds.\n",
      "Initialise Doc2Vec Model, 400 dim, process took 0:00:05.310799 seconds. (filename = ../sherlock/features/par_vec_trained_400.pkl)\n",
      "Initialised NLTK, process took 0:00:00.223828 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ritvikp/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ritvikp/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "prepare_feature_extraction()\n",
    "initialise_word_embeddings()\n",
    "initialise_pretrained_model(400)\n",
    "initialise_nltk()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bd8a42",
   "metadata": {},
   "source": [
    "## Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe171a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series(\n",
    "    [\n",
    "        [\"Jane Smith\", \"Lute Ahorn\", \"Anna James\"],\n",
    "        [\"Amsterdam\", \"Haarlem\", \"Zwolle\"],\n",
    "        [\"Chabot Street 19\", \"1200 fifth Avenue\", \"Binnenkant 22, 1011BH\"]\n",
    "    ],\n",
    "    name=\"values\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e7c63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f54ca40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features: 100%|██████████| 3/3 [00:00<00:00, 43.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting 1588 column features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "extract_features(\n",
    "    \"../temporary.csv\",\n",
    "    data\n",
    ")\n",
    "feature_vectors = pd.read_csv(\"../temporary.csv\", dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "171e17a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_[0]-agg-any</th>\n",
       "      <th>n_[0]-agg-all</th>\n",
       "      <th>n_[0]-agg-mean</th>\n",
       "      <th>n_[0]-agg-var</th>\n",
       "      <th>n_[0]-agg-min</th>\n",
       "      <th>n_[0]-agg-max</th>\n",
       "      <th>n_[0]-agg-median</th>\n",
       "      <th>n_[0]-agg-sum</th>\n",
       "      <th>n_[0]-agg-kurtosis</th>\n",
       "      <th>n_[0]-agg-skewness</th>\n",
       "      <th>...</th>\n",
       "      <th>par_vec_390</th>\n",
       "      <th>par_vec_391</th>\n",
       "      <th>par_vec_392</th>\n",
       "      <th>par_vec_393</th>\n",
       "      <th>par_vec_394</th>\n",
       "      <th>par_vec_395</th>\n",
       "      <th>par_vec_396</th>\n",
       "      <th>par_vec_397</th>\n",
       "      <th>par_vec_398</th>\n",
       "      <th>par_vec_399</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.115582</td>\n",
       "      <td>0.023616</td>\n",
       "      <td>-0.130443</td>\n",
       "      <td>0.005853</td>\n",
       "      <td>-0.134291</td>\n",
       "      <td>-0.070024</td>\n",
       "      <td>-0.051108</td>\n",
       "      <td>-0.068254</td>\n",
       "      <td>0.085618</td>\n",
       "      <td>-0.145274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054362</td>\n",
       "      <td>0.023427</td>\n",
       "      <td>-0.166515</td>\n",
       "      <td>-0.015039</td>\n",
       "      <td>-0.058927</td>\n",
       "      <td>0.008417</td>\n",
       "      <td>-0.046037</td>\n",
       "      <td>0.025094</td>\n",
       "      <td>0.036799</td>\n",
       "      <td>-0.086497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021765</td>\n",
       "      <td>0.001658</td>\n",
       "      <td>0.047552</td>\n",
       "      <td>0.118581</td>\n",
       "      <td>-0.094967</td>\n",
       "      <td>0.036038</td>\n",
       "      <td>-0.004747</td>\n",
       "      <td>-0.088888</td>\n",
       "      <td>-0.118796</td>\n",
       "      <td>-0.192545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1588 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_[0]-agg-any  n_[0]-agg-all  n_[0]-agg-mean  n_[0]-agg-var  n_[0]-agg-min  \\\n",
       "0            0.0            0.0             0.0       0.000000            0.0   \n",
       "1            0.0            0.0             0.0       0.000000            0.0   \n",
       "2            1.0            0.0             1.0       0.666667            0.0   \n",
       "\n",
       "   n_[0]-agg-max  n_[0]-agg-median  n_[0]-agg-sum  n_[0]-agg-kurtosis  \\\n",
       "0            0.0               0.0            0.0                -3.0   \n",
       "1            0.0               0.0            0.0                -3.0   \n",
       "2            2.0               1.0            3.0                -1.5   \n",
       "\n",
       "   n_[0]-agg-skewness  ...  par_vec_390  par_vec_391  par_vec_392  \\\n",
       "0                 0.0  ...    -0.115582     0.023616    -0.130443   \n",
       "1                 0.0  ...    -0.054362     0.023427    -0.166515   \n",
       "2                 0.0  ...    -0.021765     0.001658     0.047552   \n",
       "\n",
       "   par_vec_393  par_vec_394  par_vec_395  par_vec_396  par_vec_397  \\\n",
       "0     0.005853    -0.134291    -0.070024    -0.051108    -0.068254   \n",
       "1    -0.015039    -0.058927     0.008417    -0.046037     0.025094   \n",
       "2     0.118581    -0.094967     0.036038    -0.004747    -0.088888   \n",
       "\n",
       "   par_vec_398  par_vec_399  \n",
       "0     0.085618    -0.145274  \n",
       "1     0.036799    -0.086497  \n",
       "2    -0.118796    -0.192545  \n",
       "\n",
       "[3 rows x 1588 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc7fd9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a44a4dc7",
   "metadata": {},
   "source": [
    "## Initialize Sherlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95b26f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-15 15:41:27.222794: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-15 15:41:27.237056: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "/home/ritvikp/.conda/envs/sherlock/lib/python3.8/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = SherlockModel();\n",
    "model.initialize_model_from_json(with_weights=True, model_id=\"sherlock\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ab3600",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c49a20f",
   "metadata": {},
   "source": [
    "## Predict semantic type for column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1c203a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1015 15:41:31.806820 46912496407488 ag_logging.py:142] AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x2aabe20b4700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x2aabe20b4700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = model.predict(feature_vectors, \"sherlock\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a478f8cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['name', 'city', 'address'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f54562",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "dbbef01d25d9fb4d9430fa9d81ea780e18a1c669119e240c1440cbb3ef3d3f19"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
