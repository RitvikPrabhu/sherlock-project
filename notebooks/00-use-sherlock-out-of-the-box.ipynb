{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a2584dd",
   "metadata": {},
   "source": [
    "# Using Sherlock out-of-the-box\n",
    "This notebook shows how to predict a semantic type for a given table column.\n",
    "The steps are basically:\n",
    "- Download files for word embedding and paragraph vector feature extraction (downloads only once) and initialize feature extraction models.\n",
    "- Extract features from table columns.\n",
    "- Initialize Sherlock.\n",
    "- Make a prediction for the feature representation of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86625d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "from sherlock import helpers\n",
    "from sherlock.deploy.model import SherlockModel\n",
    "from sherlock.functional import extract_features_to_csv\n",
    "from sherlock.features.paragraph_vectors import initialise_pretrained_model, initialise_nltk\n",
    "from sherlock.features.preprocessing import (\n",
    "    extract_features,\n",
    "    convert_string_lists_to_lists,\n",
    "    prepare_feature_extraction,\n",
    "    load_parquet_values,\n",
    ")\n",
    "from sherlock.features.word_embeddings import initialise_word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc6b1a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTHONHASHSEED=13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'13'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%env PYTHONHASHSEED=13\n",
    "%env PYTHONHASHSEED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1101303",
   "metadata": {},
   "source": [
    "## Initialize feature extraction models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8682ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing feature extraction by downloading 4 files:\n",
      "        \n",
      " ../sherlock/features/glove.6B.50d.txt, \n",
      " ../sherlock/features/par_vec_trained_400.pkl.docvecs.vectors_docs.npy,\n",
      "        \n",
      " ../sherlock/features/par_vec_trained_400.pkl.trainables.syn1neg.npy, and \n",
      " ../sherlock/features/par_vec_trained_400.pkl.wv.vectors.npy.\n",
      "        \n",
      "All files for extracting word and paragraph embeddings are present.\n",
      "Initialising word embeddings\n",
      "Initialise Word Embeddings process took 0:00:04.833840 seconds.\n",
      "Initialise Doc2Vec Model, 400 dim, process took 0:00:02.871755 seconds. (filename = ../sherlock/features/par_vec_trained_400.pkl)\n",
      "Initialised NLTK, process took 0:00:00.106181 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ritvikp/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ritvikp/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "prepare_feature_extraction()\n",
    "initialise_word_embeddings()\n",
    "initialise_pretrained_model(400)\n",
    "initialise_nltk()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3b7967",
   "metadata": {},
   "source": [
    "## Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db04ccf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series(\n",
    "    [\n",
    "        [\"Jane Smith\", \"Lute Ahorn\", \"Anna James\"],\n",
    "        [\"Amsterdam\", \"Haarlem\", \"Zwolle\"],\n",
    "        [\"Chabot Street 19\", \"1200 fifth Avenue\", \"Binnenkant 22, 1011BH\"]\n",
    "    ],\n",
    "    name=\"values\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4875f6c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 [Jane Smith, Lute Ahorn, Anna James]\n",
       "1                         [Amsterdam, Haarlem, Zwolle]\n",
       "2    [Chabot Street 19, 1200 fifth Avenue, Binnenka...\n",
       "Name: values, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7f2c846",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features: 100%|██████████| 3/3 [00:00<00:00, 188.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting 1588 column features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "extract_features(\n",
    "    \"../temporary.csv\",\n",
    "    data\n",
    ")\n",
    "feature_vectors = pd.read_csv(\"../temporary.csv\", dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c42ce71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_[0]-agg-any</th>\n",
       "      <th>n_[0]-agg-all</th>\n",
       "      <th>n_[0]-agg-mean</th>\n",
       "      <th>n_[0]-agg-var</th>\n",
       "      <th>n_[0]-agg-min</th>\n",
       "      <th>n_[0]-agg-max</th>\n",
       "      <th>n_[0]-agg-median</th>\n",
       "      <th>n_[0]-agg-sum</th>\n",
       "      <th>n_[0]-agg-kurtosis</th>\n",
       "      <th>n_[0]-agg-skewness</th>\n",
       "      <th>...</th>\n",
       "      <th>par_vec_390</th>\n",
       "      <th>par_vec_391</th>\n",
       "      <th>par_vec_392</th>\n",
       "      <th>par_vec_393</th>\n",
       "      <th>par_vec_394</th>\n",
       "      <th>par_vec_395</th>\n",
       "      <th>par_vec_396</th>\n",
       "      <th>par_vec_397</th>\n",
       "      <th>par_vec_398</th>\n",
       "      <th>par_vec_399</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.114591</td>\n",
       "      <td>0.024789</td>\n",
       "      <td>-0.129655</td>\n",
       "      <td>0.006171</td>\n",
       "      <td>-0.135411</td>\n",
       "      <td>-0.071066</td>\n",
       "      <td>-0.052694</td>\n",
       "      <td>-0.067143</td>\n",
       "      <td>0.087397</td>\n",
       "      <td>-0.144397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053379</td>\n",
       "      <td>0.022491</td>\n",
       "      <td>-0.165058</td>\n",
       "      <td>-0.016199</td>\n",
       "      <td>-0.058179</td>\n",
       "      <td>0.008537</td>\n",
       "      <td>-0.045880</td>\n",
       "      <td>0.024186</td>\n",
       "      <td>0.038253</td>\n",
       "      <td>-0.087760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021885</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.047812</td>\n",
       "      <td>0.120439</td>\n",
       "      <td>-0.093610</td>\n",
       "      <td>0.037608</td>\n",
       "      <td>-0.004563</td>\n",
       "      <td>-0.088528</td>\n",
       "      <td>-0.117394</td>\n",
       "      <td>-0.192903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1588 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_[0]-agg-any  n_[0]-agg-all  n_[0]-agg-mean  n_[0]-agg-var  n_[0]-agg-min  \\\n",
       "0            0.0            0.0             0.0       0.000000            0.0   \n",
       "1            0.0            0.0             0.0       0.000000            0.0   \n",
       "2            1.0            0.0             1.0       0.666667            0.0   \n",
       "\n",
       "   n_[0]-agg-max  n_[0]-agg-median  n_[0]-agg-sum  n_[0]-agg-kurtosis  \\\n",
       "0            0.0               0.0            0.0                -3.0   \n",
       "1            0.0               0.0            0.0                -3.0   \n",
       "2            2.0               1.0            3.0                -1.5   \n",
       "\n",
       "   n_[0]-agg-skewness  ...  par_vec_390  par_vec_391  par_vec_392  \\\n",
       "0                 0.0  ...    -0.114591     0.024789    -0.129655   \n",
       "1                 0.0  ...    -0.053379     0.022491    -0.165058   \n",
       "2                 0.0  ...    -0.021885     0.000305     0.047812   \n",
       "\n",
       "   par_vec_393  par_vec_394  par_vec_395  par_vec_396  par_vec_397  \\\n",
       "0     0.006171    -0.135411    -0.071066    -0.052694    -0.067143   \n",
       "1    -0.016199    -0.058179     0.008537    -0.045880     0.024186   \n",
       "2     0.120439    -0.093610     0.037608    -0.004563    -0.088528   \n",
       "\n",
       "   par_vec_398  par_vec_399  \n",
       "0     0.087397    -0.144397  \n",
       "1     0.038253    -0.087760  \n",
       "2    -0.117394    -0.192903  \n",
       "\n",
       "[3 rows x 1588 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41d44ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9027fa4a",
   "metadata": {},
   "source": [
    "## Initialize Sherlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9ec13ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-23 20:58:20.694775: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-23 20:58:20.705349: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "/home/ritvikp/.conda/envs/sherlock/lib/python3.8/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = SherlockModel();\n",
    "model.initialize_model_from_json(with_weights=True, model_id=\"sherlock\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5551878e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a1ab955",
   "metadata": {},
   "source": [
    "## Predict semantic type for column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc079fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0923 20:58:21.040345 46912496407488 ag_logging.py:142] AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x2aabe32844c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x2aabe32844c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: [46]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/ritvikp/CMDA_capstone/sherlock-project/notebooks/00-use-sherlock-out-of-the-box.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Btinkercliffs1/home/ritvikp/CMDA_capstone/sherlock-project/notebooks/00-use-sherlock-out-of-the-box.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m predicted_labels \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(feature_vectors, \u001b[39m\"\u001b[39;49m\u001b[39msherlock\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/CMDA_capstone/sherlock-project/sherlock/deploy/model.py:121\u001b[0m, in \u001b[0;36mSherlockModel.predict\u001b[0;34m(self, X, model_id)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[39m\"\"\"Use sherlock model to generate predictions for X.\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \n\u001b[1;32m    109\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39mArray with predictions for X.\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    120\u001b[0m y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict_proba(X, model_id)\n\u001b[0;32m--> 121\u001b[0m y_pred_classes \u001b[39m=\u001b[39m helpers\u001b[39m.\u001b[39;49m_proba_to_classes(y_pred, model_id)\n\u001b[1;32m    123\u001b[0m \u001b[39mreturn\u001b[39;00m y_pred_classes\n",
      "File \u001b[0;32m~/CMDA_capstone/sherlock-project/sherlock/deploy/helpers.py:89\u001b[0m, in \u001b[0;36m_proba_to_classes\u001b[0;34m(y_pred, model_id)\u001b[0m\n\u001b[1;32m     84\u001b[0m encoder \u001b[39m=\u001b[39m LabelEncoder()\n\u001b[1;32m     85\u001b[0m encoder\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(\n\u001b[1;32m     86\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m../model_files/classes_\u001b[39m\u001b[39m{\u001b[39;00mmodel_id\u001b[39m}\u001b[39;00m\u001b[39m.npy\u001b[39m\u001b[39m\"\u001b[39m, allow_pickle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     87\u001b[0m )\n\u001b[0;32m---> 89\u001b[0m y_pred \u001b[39m=\u001b[39m encoder\u001b[39m.\u001b[39;49minverse_transform(y_pred_int)\n\u001b[1;32m     91\u001b[0m \u001b[39mreturn\u001b[39;00m y_pred\n",
      "File \u001b[0;32m~/python3/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:160\u001b[0m, in \u001b[0;36mLabelEncoder.inverse_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    158\u001b[0m diff \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msetdiff1d(y, np\u001b[39m.\u001b[39marange(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_)))\n\u001b[1;32m    159\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(diff):\n\u001b[0;32m--> 160\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    161\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39my contains previously unseen labels: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mstr\u001b[39m(diff))\n\u001b[1;32m    162\u001b[0m y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(y)\n\u001b[1;32m    163\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_[y]\n",
      "\u001b[0;31mValueError\u001b[0m: y contains previously unseen labels: [46]"
     ]
    }
   ],
   "source": [
    "predicted_labels = model.predict(feature_vectors, \"sherlock\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0feb9584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['person', 'city', 'address'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4efc9a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('sherlock')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "dbbef01d25d9fb4d9430fa9d81ea780e18a1c669119e240c1440cbb3ef3d3f19"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
