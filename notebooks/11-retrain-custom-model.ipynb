{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook enables training and testing of Sherlock.\n",
    "The procedure is:\n",
    "- Load train, val, test datasets (should be preprocessed)\n",
    "- Initialize model using the \"pretrained\" model or by training one from scratch.\n",
    "- Evaluate and analyse the model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTHONHASHSEED=13\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%env PYTHONHASHSEED=13\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will be the ID for the retrained model,\n",
    "#further down predictions can also be made with the original model: \"sherlock\"\n",
    "model_id = 'retrained_sherlock'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "from sherlock.deploy.model import SherlockModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets for training, validation, testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2022-10-15 17:04:14.862415\n",
      "Load data (train) process took 0:00:00.369076 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "print(f'Started at {start}')\n",
    "\n",
    "X_train = pd.read_parquet('../data/data/processed/train.parquet')\n",
    "y_train = pd.read_parquet('../data/data/raw/train_labels.parquet').values.flatten()\n",
    "\n",
    "y_train = np.array([x.lower() for x in y_train])\n",
    "\n",
    "print(f'Load data (train) process took {datetime.now() - start} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct types for columns in the Dataframe (should be all float32):\n",
      "{dtype('float32')}\n"
     ]
    }
   ],
   "source": [
    "print('Distinct types for columns in the Dataframe (should be all float32):')\n",
    "print(set(X_train.dtypes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2022-10-15 17:04:15.350004\n",
      "Load data (validation) process took 0:00:00.328007 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "print(f'Started at {start}')\n",
    "\n",
    "X_validation = pd.read_parquet('../data/data/processed/validation.parquet')\n",
    "y_validation = pd.read_parquet('../data/data/raw/val_labels.parquet').values.flatten()\n",
    "\n",
    "y_validation = np.array([x.lower() for x in y_validation])\n",
    "\n",
    "print(f'Load data (validation) process took {datetime.now() - start} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2022-10-15 17:04:15.715127\n",
      "Finished at 2022-10-15 17:04:16.726140, took 0:00:01.011024 seconds\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "print(f'Started at {start}')\n",
    "\n",
    "X_test = pd.read_parquet('../data/data/processed/test.parquet')\n",
    "y_test = pd.read_parquet('../data/data/raw/test_labels.parquet').values.flatten()\n",
    "\n",
    "y_test = np.array([x.lower() for x in y_test])\n",
    "\n",
    "print(f'Finished at {datetime.now()}, took {datetime.now() - start} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the model\n",
    "Two options:\n",
    "- Load Sherlock model with pretrained weights\n",
    "- Fit Sherlock model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"retrained_sherlock\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2022-10-15 17:04:16.798573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritvikp/.conda/envs/myenv3.8/lib/python3.8/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1015 17:04:17.378444 46912499975424 ag_logging.py:142] AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x2aab3664b280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x2aab3664b280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "254/254 [==============================] - ETA: 0s - loss: 2.0324 - categorical_accuracy: 0.5677"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1015 17:04:24.309925 46912499975424 ag_logging.py:142] AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x2aad10db0af0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x2aad10db0af0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "254/254 [==============================] - 9s 30ms/step - loss: 2.0324 - categorical_accuracy: 0.5677 - val_loss: 1.3291 - val_categorical_accuracy: 0.7495\n",
      "Epoch 2/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 1.1586 - categorical_accuracy: 0.7746 - val_loss: 0.8859 - val_categorical_accuracy: 0.8450\n",
      "Epoch 3/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.9867 - categorical_accuracy: 0.8163 - val_loss: 0.7916 - val_categorical_accuracy: 0.8692\n",
      "Epoch 4/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.9035 - categorical_accuracy: 0.8387 - val_loss: 0.7385 - val_categorical_accuracy: 0.8810\n",
      "Epoch 5/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.8493 - categorical_accuracy: 0.8522 - val_loss: 0.7043 - val_categorical_accuracy: 0.8904\n",
      "Epoch 6/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.8074 - categorical_accuracy: 0.8611 - val_loss: 0.6752 - val_categorical_accuracy: 0.8968\n",
      "Epoch 7/10000\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 0.7731 - categorical_accuracy: 0.8703 - val_loss: 0.6553 - val_categorical_accuracy: 0.9000\n",
      "Epoch 8/10000\n",
      "254/254 [==============================] - 6s 24ms/step - loss: 0.7522 - categorical_accuracy: 0.8741 - val_loss: 0.6305 - val_categorical_accuracy: 0.9059\n",
      "Epoch 9/10000\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 0.7286 - categorical_accuracy: 0.8790 - val_loss: 0.6119 - val_categorical_accuracy: 0.9106\n",
      "Epoch 10/10000\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 0.7050 - categorical_accuracy: 0.8830 - val_loss: 0.5921 - val_categorical_accuracy: 0.9147\n",
      "Epoch 11/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.6867 - categorical_accuracy: 0.8886 - val_loss: 0.5762 - val_categorical_accuracy: 0.9181\n",
      "Epoch 12/10000\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 0.6696 - categorical_accuracy: 0.8920 - val_loss: 0.5620 - val_categorical_accuracy: 0.9214\n",
      "Epoch 13/10000\n",
      "254/254 [==============================] - 6s 26ms/step - loss: 0.6536 - categorical_accuracy: 0.8956 - val_loss: 0.5476 - val_categorical_accuracy: 0.9252\n",
      "Epoch 14/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.6366 - categorical_accuracy: 0.8996 - val_loss: 0.5331 - val_categorical_accuracy: 0.9275\n",
      "Epoch 15/10000\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 0.6257 - categorical_accuracy: 0.9015 - val_loss: 0.5235 - val_categorical_accuracy: 0.9309\n",
      "Epoch 16/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.6127 - categorical_accuracy: 0.9051 - val_loss: 0.5099 - val_categorical_accuracy: 0.9327\n",
      "Epoch 17/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.5988 - categorical_accuracy: 0.9066 - val_loss: 0.4995 - val_categorical_accuracy: 0.9350\n",
      "Epoch 18/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.5870 - categorical_accuracy: 0.9098 - val_loss: 0.4925 - val_categorical_accuracy: 0.9365\n",
      "Epoch 19/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.5768 - categorical_accuracy: 0.9122 - val_loss: 0.4769 - val_categorical_accuracy: 0.9416\n",
      "Epoch 20/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.5632 - categorical_accuracy: 0.9147 - val_loss: 0.4696 - val_categorical_accuracy: 0.9435\n",
      "Epoch 21/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.5547 - categorical_accuracy: 0.9175 - val_loss: 0.4610 - val_categorical_accuracy: 0.9445\n",
      "Epoch 22/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.5430 - categorical_accuracy: 0.9187 - val_loss: 0.4526 - val_categorical_accuracy: 0.9460\n",
      "Epoch 23/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.5368 - categorical_accuracy: 0.9196 - val_loss: 0.4432 - val_categorical_accuracy: 0.9483\n",
      "Epoch 24/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.5258 - categorical_accuracy: 0.9226 - val_loss: 0.4386 - val_categorical_accuracy: 0.9499\n",
      "Epoch 25/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.5165 - categorical_accuracy: 0.9250 - val_loss: 0.4316 - val_categorical_accuracy: 0.9517\n",
      "Epoch 26/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.5093 - categorical_accuracy: 0.9261 - val_loss: 0.4203 - val_categorical_accuracy: 0.9529\n",
      "Epoch 27/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.4993 - categorical_accuracy: 0.9274 - val_loss: 0.4147 - val_categorical_accuracy: 0.9547\n",
      "Epoch 28/10000\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 0.4929 - categorical_accuracy: 0.9293 - val_loss: 0.4085 - val_categorical_accuracy: 0.9561\n",
      "Epoch 29/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.4825 - categorical_accuracy: 0.9311 - val_loss: 0.4027 - val_categorical_accuracy: 0.9581\n",
      "Epoch 30/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.4807 - categorical_accuracy: 0.9320 - val_loss: 0.3992 - val_categorical_accuracy: 0.9567\n",
      "Epoch 31/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.4732 - categorical_accuracy: 0.9329 - val_loss: 0.3899 - val_categorical_accuracy: 0.9596\n",
      "Epoch 32/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.4629 - categorical_accuracy: 0.9355 - val_loss: 0.3845 - val_categorical_accuracy: 0.9612\n",
      "Epoch 33/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.4534 - categorical_accuracy: 0.9375 - val_loss: 0.3809 - val_categorical_accuracy: 0.9618\n",
      "Epoch 34/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.4509 - categorical_accuracy: 0.9382 - val_loss: 0.3771 - val_categorical_accuracy: 0.9618\n",
      "Epoch 35/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.4433 - categorical_accuracy: 0.9397 - val_loss: 0.3695 - val_categorical_accuracy: 0.9640\n",
      "Epoch 36/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.4405 - categorical_accuracy: 0.9396 - val_loss: 0.3639 - val_categorical_accuracy: 0.9657\n",
      "Epoch 37/10000\n",
      "254/254 [==============================] - 7s 29ms/step - loss: 0.4333 - categorical_accuracy: 0.9411 - val_loss: 0.3611 - val_categorical_accuracy: 0.9642\n",
      "Epoch 38/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.4281 - categorical_accuracy: 0.9424 - val_loss: 0.3553 - val_categorical_accuracy: 0.9666\n",
      "Epoch 39/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.4230 - categorical_accuracy: 0.9431 - val_loss: 0.3533 - val_categorical_accuracy: 0.9668\n",
      "Epoch 40/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.4147 - categorical_accuracy: 0.9460 - val_loss: 0.3492 - val_categorical_accuracy: 0.9675\n",
      "Epoch 41/10000\n",
      "254/254 [==============================] - 7s 29ms/step - loss: 0.4077 - categorical_accuracy: 0.9478 - val_loss: 0.3440 - val_categorical_accuracy: 0.9687\n",
      "Epoch 42/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.4048 - categorical_accuracy: 0.9476 - val_loss: 0.3397 - val_categorical_accuracy: 0.9700\n",
      "Epoch 43/10000\n",
      "254/254 [==============================] - 7s 29ms/step - loss: 0.4012 - categorical_accuracy: 0.9477 - val_loss: 0.3386 - val_categorical_accuracy: 0.9694\n",
      "Epoch 44/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.3980 - categorical_accuracy: 0.9477 - val_loss: 0.3343 - val_categorical_accuracy: 0.9697\n",
      "Epoch 45/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.3937 - categorical_accuracy: 0.9499 - val_loss: 0.3293 - val_categorical_accuracy: 0.9708\n",
      "Epoch 46/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254/254 [==============================] - 7s 26ms/step - loss: 0.3866 - categorical_accuracy: 0.9507 - val_loss: 0.3265 - val_categorical_accuracy: 0.9723\n",
      "Epoch 47/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.3844 - categorical_accuracy: 0.9512 - val_loss: 0.3252 - val_categorical_accuracy: 0.9717\n",
      "Epoch 48/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.3820 - categorical_accuracy: 0.9512 - val_loss: 0.3228 - val_categorical_accuracy: 0.9727\n",
      "Epoch 49/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.3730 - categorical_accuracy: 0.9533 - val_loss: 0.3162 - val_categorical_accuracy: 0.9730\n",
      "Epoch 50/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.3718 - categorical_accuracy: 0.9535 - val_loss: 0.3153 - val_categorical_accuracy: 0.9733\n",
      "Epoch 51/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.3696 - categorical_accuracy: 0.9529 - val_loss: 0.3122 - val_categorical_accuracy: 0.9742\n",
      "Epoch 52/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.3622 - categorical_accuracy: 0.9552 - val_loss: 0.3095 - val_categorical_accuracy: 0.9737\n",
      "Epoch 53/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.3591 - categorical_accuracy: 0.9559 - val_loss: 0.3057 - val_categorical_accuracy: 0.9742\n",
      "Epoch 54/10000\n",
      "254/254 [==============================] - 7s 29ms/step - loss: 0.3555 - categorical_accuracy: 0.9562 - val_loss: 0.3034 - val_categorical_accuracy: 0.9743\n",
      "Epoch 55/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.3545 - categorical_accuracy: 0.9560 - val_loss: 0.2995 - val_categorical_accuracy: 0.9756\n",
      "Epoch 56/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.3480 - categorical_accuracy: 0.9576 - val_loss: 0.2974 - val_categorical_accuracy: 0.9754\n",
      "Epoch 57/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.3452 - categorical_accuracy: 0.9582 - val_loss: 0.2974 - val_categorical_accuracy: 0.9751\n",
      "Epoch 58/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.3438 - categorical_accuracy: 0.9583 - val_loss: 0.2931 - val_categorical_accuracy: 0.9756\n",
      "Epoch 59/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.3393 - categorical_accuracy: 0.9585 - val_loss: 0.2906 - val_categorical_accuracy: 0.9759\n",
      "Epoch 60/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.3359 - categorical_accuracy: 0.9602 - val_loss: 0.2887 - val_categorical_accuracy: 0.9762\n",
      "Epoch 61/10000\n",
      "254/254 [==============================] - 7s 29ms/step - loss: 0.3313 - categorical_accuracy: 0.9606 - val_loss: 0.2887 - val_categorical_accuracy: 0.9759\n",
      "Epoch 62/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.3301 - categorical_accuracy: 0.9609 - val_loss: 0.2842 - val_categorical_accuracy: 0.9764\n",
      "Epoch 63/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.3278 - categorical_accuracy: 0.9605 - val_loss: 0.2806 - val_categorical_accuracy: 0.9778\n",
      "Epoch 64/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.3240 - categorical_accuracy: 0.9606 - val_loss: 0.2788 - val_categorical_accuracy: 0.9783\n",
      "Epoch 65/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.3218 - categorical_accuracy: 0.9610 - val_loss: 0.2779 - val_categorical_accuracy: 0.9781\n",
      "Epoch 66/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.3207 - categorical_accuracy: 0.9616 - val_loss: 0.2775 - val_categorical_accuracy: 0.9772\n",
      "Epoch 67/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.3162 - categorical_accuracy: 0.9629 - val_loss: 0.2724 - val_categorical_accuracy: 0.9784\n",
      "Epoch 68/10000\n",
      "254/254 [==============================] - 7s 29ms/step - loss: 0.3131 - categorical_accuracy: 0.9627 - val_loss: 0.2730 - val_categorical_accuracy: 0.9775\n",
      "Epoch 69/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.3084 - categorical_accuracy: 0.9639 - val_loss: 0.2698 - val_categorical_accuracy: 0.9783\n",
      "Epoch 70/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.3058 - categorical_accuracy: 0.9646 - val_loss: 0.2665 - val_categorical_accuracy: 0.9783\n",
      "Epoch 71/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.3057 - categorical_accuracy: 0.9642 - val_loss: 0.2653 - val_categorical_accuracy: 0.9779\n",
      "Epoch 72/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.3021 - categorical_accuracy: 0.9649 - val_loss: 0.2652 - val_categorical_accuracy: 0.9781\n",
      "Epoch 73/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.3015 - categorical_accuracy: 0.9635 - val_loss: 0.2633 - val_categorical_accuracy: 0.9790\n",
      "Epoch 74/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.2983 - categorical_accuracy: 0.9646 - val_loss: 0.2628 - val_categorical_accuracy: 0.9792\n",
      "Epoch 75/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.2962 - categorical_accuracy: 0.9650 - val_loss: 0.2588 - val_categorical_accuracy: 0.9800\n",
      "Epoch 76/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.2951 - categorical_accuracy: 0.9655 - val_loss: 0.2572 - val_categorical_accuracy: 0.9788\n",
      "Epoch 77/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.2904 - categorical_accuracy: 0.9660 - val_loss: 0.2561 - val_categorical_accuracy: 0.9791\n",
      "Epoch 78/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.2886 - categorical_accuracy: 0.9664 - val_loss: 0.2543 - val_categorical_accuracy: 0.9795\n",
      "Epoch 79/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.2871 - categorical_accuracy: 0.9675 - val_loss: 0.2539 - val_categorical_accuracy: 0.9791\n",
      "Epoch 80/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.2848 - categorical_accuracy: 0.9672 - val_loss: 0.2496 - val_categorical_accuracy: 0.9798\n",
      "Epoch 81/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.2810 - categorical_accuracy: 0.9681 - val_loss: 0.2463 - val_categorical_accuracy: 0.9800\n",
      "Epoch 82/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.2815 - categorical_accuracy: 0.9666 - val_loss: 0.2480 - val_categorical_accuracy: 0.9803\n",
      "Epoch 83/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.2786 - categorical_accuracy: 0.9678 - val_loss: 0.2444 - val_categorical_accuracy: 0.9809\n",
      "Epoch 84/10000\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 0.2781 - categorical_accuracy: 0.9673 - val_loss: 0.2422 - val_categorical_accuracy: 0.9816\n",
      "Epoch 85/10000\n",
      "254/254 [==============================] - 6s 26ms/step - loss: 0.2749 - categorical_accuracy: 0.9678 - val_loss: 0.2424 - val_categorical_accuracy: 0.9808\n",
      "Epoch 86/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.2713 - categorical_accuracy: 0.9687 - val_loss: 0.2394 - val_categorical_accuracy: 0.9812\n",
      "Epoch 87/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.2708 - categorical_accuracy: 0.9683 - val_loss: 0.2397 - val_categorical_accuracy: 0.9810\n",
      "Epoch 88/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.2668 - categorical_accuracy: 0.9691 - val_loss: 0.2370 - val_categorical_accuracy: 0.9816\n",
      "Epoch 89/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.2674 - categorical_accuracy: 0.9691 - val_loss: 0.2362 - val_categorical_accuracy: 0.9816\n",
      "Epoch 90/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.2639 - categorical_accuracy: 0.9700 - val_loss: 0.2326 - val_categorical_accuracy: 0.9819\n",
      "Epoch 91/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.2648 - categorical_accuracy: 0.9688 - val_loss: 0.2327 - val_categorical_accuracy: 0.9812\n",
      "Epoch 92/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.2601 - categorical_accuracy: 0.9702 - val_loss: 0.2309 - val_categorical_accuracy: 0.9816\n",
      "Epoch 93/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.2583 - categorical_accuracy: 0.9700 - val_loss: 0.2279 - val_categorical_accuracy: 0.9819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.2572 - categorical_accuracy: 0.9703 - val_loss: 0.2261 - val_categorical_accuracy: 0.9827\n",
      "Epoch 95/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.2517 - categorical_accuracy: 0.9721 - val_loss: 0.2255 - val_categorical_accuracy: 0.9827\n",
      "Epoch 96/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.2542 - categorical_accuracy: 0.9707 - val_loss: 0.2262 - val_categorical_accuracy: 0.9816\n",
      "Epoch 97/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.2519 - categorical_accuracy: 0.9710 - val_loss: 0.2238 - val_categorical_accuracy: 0.9821\n",
      "Epoch 98/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.2508 - categorical_accuracy: 0.9712 - val_loss: 0.2238 - val_categorical_accuracy: 0.9808\n",
      "Epoch 99/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.2478 - categorical_accuracy: 0.9718 - val_loss: 0.2206 - val_categorical_accuracy: 0.9822\n",
      "Epoch 100/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.2474 - categorical_accuracy: 0.9716 - val_loss: 0.2187 - val_categorical_accuracy: 0.9820\n",
      "Epoch 101/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.2450 - categorical_accuracy: 0.9719 - val_loss: 0.2178 - val_categorical_accuracy: 0.9819\n",
      "Epoch 102/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.2451 - categorical_accuracy: 0.9714 - val_loss: 0.2167 - val_categorical_accuracy: 0.9827\n",
      "Epoch 103/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.2417 - categorical_accuracy: 0.9719 - val_loss: 0.2144 - val_categorical_accuracy: 0.9827\n",
      "Epoch 104/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.2409 - categorical_accuracy: 0.9716 - val_loss: 0.2140 - val_categorical_accuracy: 0.9827\n",
      "Epoch 105/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.2378 - categorical_accuracy: 0.9726 - val_loss: 0.2113 - val_categorical_accuracy: 0.9830\n",
      "Epoch 106/10000\n",
      "254/254 [==============================] - 7s 29ms/step - loss: 0.2375 - categorical_accuracy: 0.9727 - val_loss: 0.2097 - val_categorical_accuracy: 0.9835\n",
      "Epoch 107/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.2356 - categorical_accuracy: 0.9735 - val_loss: 0.2103 - val_categorical_accuracy: 0.9826\n",
      "Epoch 108/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.2371 - categorical_accuracy: 0.9717 - val_loss: 0.2113 - val_categorical_accuracy: 0.9833\n",
      "Epoch 109/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.2330 - categorical_accuracy: 0.9730 - val_loss: 0.2072 - val_categorical_accuracy: 0.9833\n",
      "Epoch 110/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.2328 - categorical_accuracy: 0.9724 - val_loss: 0.2049 - val_categorical_accuracy: 0.9835\n",
      "Epoch 111/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.2286 - categorical_accuracy: 0.9738 - val_loss: 0.2032 - val_categorical_accuracy: 0.9836\n",
      "Epoch 112/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.2297 - categorical_accuracy: 0.9730 - val_loss: 0.2043 - val_categorical_accuracy: 0.9834\n",
      "Epoch 113/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.2278 - categorical_accuracy: 0.9735 - val_loss: 0.2024 - val_categorical_accuracy: 0.9840\n",
      "Epoch 114/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.2260 - categorical_accuracy: 0.9738 - val_loss: 0.2001 - val_categorical_accuracy: 0.9834\n",
      "Epoch 115/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.2250 - categorical_accuracy: 0.9739 - val_loss: 0.1994 - val_categorical_accuracy: 0.9840\n",
      "Epoch 116/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.2245 - categorical_accuracy: 0.9734 - val_loss: 0.1994 - val_categorical_accuracy: 0.9835\n",
      "Epoch 117/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.2234 - categorical_accuracy: 0.9736 - val_loss: 0.1984 - val_categorical_accuracy: 0.9832\n",
      "Epoch 118/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.2191 - categorical_accuracy: 0.9743 - val_loss: 0.1992 - val_categorical_accuracy: 0.9829\n",
      "Epoch 119/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.2210 - categorical_accuracy: 0.9742 - val_loss: 0.1960 - val_categorical_accuracy: 0.9836\n",
      "Epoch 120/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.2170 - categorical_accuracy: 0.9744 - val_loss: 0.1959 - val_categorical_accuracy: 0.9842\n",
      "Epoch 121/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.2162 - categorical_accuracy: 0.9750 - val_loss: 0.1940 - val_categorical_accuracy: 0.9839\n",
      "Epoch 122/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.2149 - categorical_accuracy: 0.9746 - val_loss: 0.1937 - val_categorical_accuracy: 0.9838\n",
      "Epoch 123/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.2148 - categorical_accuracy: 0.9746 - val_loss: 0.1913 - val_categorical_accuracy: 0.9841\n",
      "Epoch 124/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.2115 - categorical_accuracy: 0.9751 - val_loss: 0.1910 - val_categorical_accuracy: 0.9841\n",
      "Epoch 125/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.2122 - categorical_accuracy: 0.9747 - val_loss: 0.1911 - val_categorical_accuracy: 0.9829\n",
      "Epoch 126/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.2114 - categorical_accuracy: 0.9744 - val_loss: 0.1872 - val_categorical_accuracy: 0.9842\n",
      "Epoch 127/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.2094 - categorical_accuracy: 0.9755 - val_loss: 0.1878 - val_categorical_accuracy: 0.9845\n",
      "Epoch 128/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.2086 - categorical_accuracy: 0.9757 - val_loss: 0.1870 - val_categorical_accuracy: 0.9831\n",
      "Epoch 129/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.2076 - categorical_accuracy: 0.9756 - val_loss: 0.1852 - val_categorical_accuracy: 0.9841\n",
      "Epoch 130/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.2061 - categorical_accuracy: 0.9755 - val_loss: 0.1852 - val_categorical_accuracy: 0.9837\n",
      "Epoch 131/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.2066 - categorical_accuracy: 0.9747 - val_loss: 0.1835 - val_categorical_accuracy: 0.9845\n",
      "Epoch 132/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.2047 - categorical_accuracy: 0.9751 - val_loss: 0.1828 - val_categorical_accuracy: 0.9843\n",
      "Epoch 133/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.2014 - categorical_accuracy: 0.9766 - val_loss: 0.1806 - val_categorical_accuracy: 0.9848\n",
      "Epoch 134/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.2022 - categorical_accuracy: 0.9761 - val_loss: 0.1810 - val_categorical_accuracy: 0.9844\n",
      "Epoch 135/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.2008 - categorical_accuracy: 0.9758 - val_loss: 0.1788 - val_categorical_accuracy: 0.9840\n",
      "Epoch 136/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.2010 - categorical_accuracy: 0.9758 - val_loss: 0.1796 - val_categorical_accuracy: 0.9835\n",
      "Epoch 137/10000\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 0.1992 - categorical_accuracy: 0.9756 - val_loss: 0.1780 - val_categorical_accuracy: 0.9849\n",
      "Epoch 138/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.1967 - categorical_accuracy: 0.9769 - val_loss: 0.1783 - val_categorical_accuracy: 0.9848\n",
      "Epoch 139/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.1962 - categorical_accuracy: 0.9763 - val_loss: 0.1754 - val_categorical_accuracy: 0.9845\n",
      "Epoch 140/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.1967 - categorical_accuracy: 0.9756 - val_loss: 0.1744 - val_categorical_accuracy: 0.9844\n",
      "Epoch 141/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.1945 - categorical_accuracy: 0.9768 - val_loss: 0.1722 - val_categorical_accuracy: 0.9849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.1937 - categorical_accuracy: 0.9765 - val_loss: 0.1723 - val_categorical_accuracy: 0.9839\n",
      "Epoch 143/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.1942 - categorical_accuracy: 0.9762 - val_loss: 0.1713 - val_categorical_accuracy: 0.9847\n",
      "Epoch 144/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.1933 - categorical_accuracy: 0.9758 - val_loss: 0.1709 - val_categorical_accuracy: 0.9851\n",
      "Epoch 145/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.1908 - categorical_accuracy: 0.9768 - val_loss: 0.1706 - val_categorical_accuracy: 0.9850\n",
      "Epoch 146/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.1904 - categorical_accuracy: 0.9770 - val_loss: 0.1710 - val_categorical_accuracy: 0.9848\n",
      "Epoch 147/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.1886 - categorical_accuracy: 0.9772 - val_loss: 0.1716 - val_categorical_accuracy: 0.9840\n",
      "Epoch 148/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.1892 - categorical_accuracy: 0.9763 - val_loss: 0.1676 - val_categorical_accuracy: 0.9850\n",
      "Epoch 149/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.1877 - categorical_accuracy: 0.9765 - val_loss: 0.1675 - val_categorical_accuracy: 0.9853\n",
      "Epoch 150/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.1866 - categorical_accuracy: 0.9772 - val_loss: 0.1678 - val_categorical_accuracy: 0.9848\n",
      "Epoch 151/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.1854 - categorical_accuracy: 0.9769 - val_loss: 0.1655 - val_categorical_accuracy: 0.9848\n",
      "Epoch 152/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.1858 - categorical_accuracy: 0.9770 - val_loss: 0.1660 - val_categorical_accuracy: 0.9850\n",
      "Epoch 153/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.1843 - categorical_accuracy: 0.9772 - val_loss: 0.1660 - val_categorical_accuracy: 0.9845\n",
      "Epoch 154/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.1820 - categorical_accuracy: 0.9776 - val_loss: 0.1659 - val_categorical_accuracy: 0.9845\n",
      "Epoch 155/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.1823 - categorical_accuracy: 0.9771 - val_loss: 0.1664 - val_categorical_accuracy: 0.9848\n",
      "Epoch 156/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.1808 - categorical_accuracy: 0.9777 - val_loss: 0.1638 - val_categorical_accuracy: 0.9850\n",
      "Epoch 157/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.1817 - categorical_accuracy: 0.9771 - val_loss: 0.1647 - val_categorical_accuracy: 0.9845\n",
      "Epoch 158/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.1811 - categorical_accuracy: 0.9775 - val_loss: 0.1629 - val_categorical_accuracy: 0.9849\n",
      "Epoch 159/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.1795 - categorical_accuracy: 0.9777 - val_loss: 0.1617 - val_categorical_accuracy: 0.9850\n",
      "Epoch 160/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.1793 - categorical_accuracy: 0.9775 - val_loss: 0.1608 - val_categorical_accuracy: 0.9853\n",
      "Epoch 161/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.1778 - categorical_accuracy: 0.9775 - val_loss: 0.1586 - val_categorical_accuracy: 0.9851\n",
      "Epoch 162/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.1784 - categorical_accuracy: 0.9771 - val_loss: 0.1590 - val_categorical_accuracy: 0.9853\n",
      "Epoch 163/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.1753 - categorical_accuracy: 0.9780 - val_loss: 0.1577 - val_categorical_accuracy: 0.9851\n",
      "Epoch 164/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.1749 - categorical_accuracy: 0.9784 - val_loss: 0.1580 - val_categorical_accuracy: 0.9851\n",
      "Epoch 165/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.1761 - categorical_accuracy: 0.9775 - val_loss: 0.1563 - val_categorical_accuracy: 0.9853\n",
      "Epoch 166/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.1722 - categorical_accuracy: 0.9788 - val_loss: 0.1564 - val_categorical_accuracy: 0.9851\n",
      "Epoch 167/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.1715 - categorical_accuracy: 0.9785 - val_loss: 0.1554 - val_categorical_accuracy: 0.9850\n",
      "Epoch 168/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.1719 - categorical_accuracy: 0.9788 - val_loss: 0.1549 - val_categorical_accuracy: 0.9850\n",
      "Epoch 169/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.1706 - categorical_accuracy: 0.9785 - val_loss: 0.1542 - val_categorical_accuracy: 0.9850\n",
      "Epoch 170/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.1701 - categorical_accuracy: 0.9786 - val_loss: 0.1517 - val_categorical_accuracy: 0.9858\n",
      "Epoch 171/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.1703 - categorical_accuracy: 0.9780 - val_loss: 0.1518 - val_categorical_accuracy: 0.9850\n",
      "Epoch 172/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.1688 - categorical_accuracy: 0.9791 - val_loss: 0.1514 - val_categorical_accuracy: 0.9848\n",
      "Epoch 173/10000\n",
      "254/254 [==============================] - 7s 29ms/step - loss: 0.1679 - categorical_accuracy: 0.9788 - val_loss: 0.1506 - val_categorical_accuracy: 0.9850\n",
      "Epoch 174/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.1686 - categorical_accuracy: 0.9782 - val_loss: 0.1500 - val_categorical_accuracy: 0.9855\n",
      "Epoch 175/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.1684 - categorical_accuracy: 0.9783 - val_loss: 0.1487 - val_categorical_accuracy: 0.9854\n",
      "Epoch 176/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.1692 - categorical_accuracy: 0.9781 - val_loss: 0.1521 - val_categorical_accuracy: 0.9846\n",
      "Epoch 177/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.1660 - categorical_accuracy: 0.9789 - val_loss: 0.1487 - val_categorical_accuracy: 0.9851\n",
      "Epoch 178/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.1660 - categorical_accuracy: 0.9785 - val_loss: 0.1478 - val_categorical_accuracy: 0.9856\n",
      "Epoch 179/10000\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 0.1660 - categorical_accuracy: 0.9787 - val_loss: 0.1473 - val_categorical_accuracy: 0.9856\n",
      "Epoch 180/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.1638 - categorical_accuracy: 0.9787 - val_loss: 0.1458 - val_categorical_accuracy: 0.9854\n",
      "Epoch 181/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.1653 - categorical_accuracy: 0.9782 - val_loss: 0.1462 - val_categorical_accuracy: 0.9855\n",
      "Epoch 182/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.1635 - categorical_accuracy: 0.9787 - val_loss: 0.1466 - val_categorical_accuracy: 0.9857\n",
      "Epoch 183/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.1622 - categorical_accuracy: 0.9792 - val_loss: 0.1458 - val_categorical_accuracy: 0.9851\n",
      "Epoch 184/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.1614 - categorical_accuracy: 0.9789 - val_loss: 0.1453 - val_categorical_accuracy: 0.9854\n",
      "Epoch 185/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.1613 - categorical_accuracy: 0.9791 - val_loss: 0.1435 - val_categorical_accuracy: 0.9861\n",
      "Epoch 186/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.1606 - categorical_accuracy: 0.9796 - val_loss: 0.1425 - val_categorical_accuracy: 0.9857\n",
      "Epoch 187/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.1616 - categorical_accuracy: 0.9789 - val_loss: 0.1422 - val_categorical_accuracy: 0.9858\n",
      "Epoch 188/10000\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 0.1603 - categorical_accuracy: 0.9787 - val_loss: 0.1429 - val_categorical_accuracy: 0.9853\n",
      "Epoch 189/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254/254 [==============================] - 6s 25ms/step - loss: 0.1596 - categorical_accuracy: 0.9793 - val_loss: 0.1431 - val_categorical_accuracy: 0.9860\n",
      "Epoch 190/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.1592 - categorical_accuracy: 0.9791 - val_loss: 0.1419 - val_categorical_accuracy: 0.9855\n",
      "Epoch 191/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.1576 - categorical_accuracy: 0.9796 - val_loss: 0.1416 - val_categorical_accuracy: 0.9856\n",
      "Epoch 192/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.1577 - categorical_accuracy: 0.9797 - val_loss: 0.1405 - val_categorical_accuracy: 0.9859\n",
      "Epoch 193/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.1573 - categorical_accuracy: 0.9791 - val_loss: 0.1410 - val_categorical_accuracy: 0.9852\n",
      "Epoch 194/10000\n",
      "254/254 [==============================] - 8s 30ms/step - loss: 0.1570 - categorical_accuracy: 0.9786 - val_loss: 0.1387 - val_categorical_accuracy: 0.9859\n",
      "Epoch 195/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.1555 - categorical_accuracy: 0.9795 - val_loss: 0.1391 - val_categorical_accuracy: 0.9862\n",
      "Epoch 196/10000\n",
      "254/254 [==============================] - 7s 29ms/step - loss: 0.1553 - categorical_accuracy: 0.9792 - val_loss: 0.1380 - val_categorical_accuracy: 0.9862\n",
      "Epoch 197/10000\n",
      "254/254 [==============================] - 7s 29ms/step - loss: 0.1552 - categorical_accuracy: 0.9796 - val_loss: 0.1397 - val_categorical_accuracy: 0.9854\n",
      "Epoch 198/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.1545 - categorical_accuracy: 0.9798 - val_loss: 0.1378 - val_categorical_accuracy: 0.9859\n",
      "Epoch 199/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.1546 - categorical_accuracy: 0.9796 - val_loss: 0.1383 - val_categorical_accuracy: 0.9853\n",
      "Epoch 200/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.1519 - categorical_accuracy: 0.9795 - val_loss: 0.1378 - val_categorical_accuracy: 0.9858\n",
      "Epoch 201/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.1529 - categorical_accuracy: 0.9799 - val_loss: 0.1366 - val_categorical_accuracy: 0.9860\n",
      "Epoch 202/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.1522 - categorical_accuracy: 0.9800 - val_loss: 0.1350 - val_categorical_accuracy: 0.9859\n",
      "Epoch 203/10000\n",
      "254/254 [==============================] - 7s 29ms/step - loss: 0.1521 - categorical_accuracy: 0.9797 - val_loss: 0.1354 - val_categorical_accuracy: 0.9852\n",
      "Epoch 204/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.1527 - categorical_accuracy: 0.9798 - val_loss: 0.1361 - val_categorical_accuracy: 0.9858\n",
      "Epoch 205/10000\n",
      "254/254 [==============================] - 7s 29ms/step - loss: 0.1515 - categorical_accuracy: 0.9796 - val_loss: 0.1343 - val_categorical_accuracy: 0.9865\n",
      "Epoch 206/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.1503 - categorical_accuracy: 0.9800 - val_loss: 0.1341 - val_categorical_accuracy: 0.9863\n",
      "Epoch 207/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.1491 - categorical_accuracy: 0.9803 - val_loss: 0.1347 - val_categorical_accuracy: 0.9861\n",
      "Epoch 208/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.1497 - categorical_accuracy: 0.9800 - val_loss: 0.1345 - val_categorical_accuracy: 0.9864\n",
      "Epoch 209/10000\n",
      "254/254 [==============================] - 7s 29ms/step - loss: 0.1491 - categorical_accuracy: 0.9803 - val_loss: 0.1332 - val_categorical_accuracy: 0.9863\n",
      "Epoch 210/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.1479 - categorical_accuracy: 0.9802 - val_loss: 0.1331 - val_categorical_accuracy: 0.9860\n",
      "Epoch 211/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.1483 - categorical_accuracy: 0.9802 - val_loss: 0.1326 - val_categorical_accuracy: 0.9861\n",
      "Epoch 212/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.1472 - categorical_accuracy: 0.9803 - val_loss: 0.1319 - val_categorical_accuracy: 0.9862\n",
      "Epoch 213/10000\n",
      "254/254 [==============================] - 7s 29ms/step - loss: 0.1468 - categorical_accuracy: 0.9800 - val_loss: 0.1326 - val_categorical_accuracy: 0.9852\n",
      "Epoch 214/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.1469 - categorical_accuracy: 0.9800 - val_loss: 0.1319 - val_categorical_accuracy: 0.9862\n",
      "Epoch 215/10000\n",
      "254/254 [==============================] - 7s 29ms/step - loss: 0.1477 - categorical_accuracy: 0.9800 - val_loss: 0.1312 - val_categorical_accuracy: 0.9865\n",
      "Epoch 216/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.1470 - categorical_accuracy: 0.9796 - val_loss: 0.1334 - val_categorical_accuracy: 0.9865\n",
      "Epoch 217/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.1445 - categorical_accuracy: 0.9802 - val_loss: 0.1333 - val_categorical_accuracy: 0.9862\n",
      "Epoch 218/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.1463 - categorical_accuracy: 0.9799 - val_loss: 0.1311 - val_categorical_accuracy: 0.9866\n",
      "Epoch 219/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.1449 - categorical_accuracy: 0.9800 - val_loss: 0.1305 - val_categorical_accuracy: 0.9865\n",
      "Epoch 220/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.1464 - categorical_accuracy: 0.9796 - val_loss: 0.1312 - val_categorical_accuracy: 0.9862\n",
      "Epoch 221/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.1442 - categorical_accuracy: 0.9803 - val_loss: 0.1310 - val_categorical_accuracy: 0.9863\n",
      "Epoch 222/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.1435 - categorical_accuracy: 0.9804 - val_loss: 0.1307 - val_categorical_accuracy: 0.9864\n",
      "Epoch 223/10000\n",
      "254/254 [==============================] - 7s 29ms/step - loss: 0.1439 - categorical_accuracy: 0.9807 - val_loss: 0.1295 - val_categorical_accuracy: 0.9863\n",
      "Epoch 224/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.1429 - categorical_accuracy: 0.9807 - val_loss: 0.1292 - val_categorical_accuracy: 0.9866\n",
      "Epoch 225/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.1419 - categorical_accuracy: 0.9806 - val_loss: 0.1301 - val_categorical_accuracy: 0.9862\n",
      "Epoch 226/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.1452 - categorical_accuracy: 0.9797 - val_loss: 0.1306 - val_categorical_accuracy: 0.9867\n",
      "Epoch 227/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.1421 - categorical_accuracy: 0.9807 - val_loss: 0.1305 - val_categorical_accuracy: 0.9855\n",
      "Epoch 228/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.1404 - categorical_accuracy: 0.9811 - val_loss: 0.1296 - val_categorical_accuracy: 0.9862\n",
      "Epoch 229/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.1406 - categorical_accuracy: 0.9814 - val_loss: 0.1268 - val_categorical_accuracy: 0.9866\n",
      "Epoch 230/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.1407 - categorical_accuracy: 0.9811 - val_loss: 0.1274 - val_categorical_accuracy: 0.9864\n",
      "Epoch 231/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.1416 - categorical_accuracy: 0.9795 - val_loss: 0.1282 - val_categorical_accuracy: 0.9860\n",
      "Epoch 232/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.1399 - categorical_accuracy: 0.9804 - val_loss: 0.1267 - val_categorical_accuracy: 0.9862\n",
      "Epoch 233/10000\n",
      "254/254 [==============================] - 7s 29ms/step - loss: 0.1400 - categorical_accuracy: 0.9804 - val_loss: 0.1270 - val_categorical_accuracy: 0.9861\n",
      "Epoch 234/10000\n",
      "254/254 [==============================] - 7s 29ms/step - loss: 0.1394 - categorical_accuracy: 0.9806 - val_loss: 0.1266 - val_categorical_accuracy: 0.9857\n",
      "Epoch 235/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.1404 - categorical_accuracy: 0.9807 - val_loss: 0.1241 - val_categorical_accuracy: 0.9867\n",
      "Epoch 236/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.1395 - categorical_accuracy: 0.9808 - val_loss: 0.1242 - val_categorical_accuracy: 0.9863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 237/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.1394 - categorical_accuracy: 0.9805 - val_loss: 0.1235 - val_categorical_accuracy: 0.9865\n",
      "Epoch 238/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.1383 - categorical_accuracy: 0.9807 - val_loss: 0.1227 - val_categorical_accuracy: 0.9864\n",
      "Epoch 239/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.1371 - categorical_accuracy: 0.9812 - val_loss: 0.1233 - val_categorical_accuracy: 0.9865\n",
      "Epoch 240/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.1388 - categorical_accuracy: 0.9806 - val_loss: 0.1233 - val_categorical_accuracy: 0.9860\n",
      "Epoch 241/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.1369 - categorical_accuracy: 0.9806 - val_loss: 0.1223 - val_categorical_accuracy: 0.9867\n",
      "Epoch 242/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.1368 - categorical_accuracy: 0.9809 - val_loss: 0.1230 - val_categorical_accuracy: 0.9867\n",
      "Epoch 243/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.1370 - categorical_accuracy: 0.9808 - val_loss: 0.1211 - val_categorical_accuracy: 0.9867\n",
      "Epoch 244/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.1362 - categorical_accuracy: 0.9812 - val_loss: 0.1208 - val_categorical_accuracy: 0.9868\n",
      "Epoch 245/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.1363 - categorical_accuracy: 0.9806 - val_loss: 0.1206 - val_categorical_accuracy: 0.9865\n",
      "Epoch 246/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.1362 - categorical_accuracy: 0.9805 - val_loss: 0.1216 - val_categorical_accuracy: 0.9866\n",
      "Epoch 247/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.1342 - categorical_accuracy: 0.9814 - val_loss: 0.1201 - val_categorical_accuracy: 0.9865\n",
      "Epoch 248/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.1346 - categorical_accuracy: 0.9808 - val_loss: 0.1219 - val_categorical_accuracy: 0.9858\n",
      "Epoch 249/10000\n",
      "254/254 [==============================] - 7s 30ms/step - loss: 0.1346 - categorical_accuracy: 0.9807 - val_loss: 0.1200 - val_categorical_accuracy: 0.9868\n",
      "Epoch 250/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.1353 - categorical_accuracy: 0.9805 - val_loss: 0.1186 - val_categorical_accuracy: 0.9871\n",
      "Epoch 251/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.1352 - categorical_accuracy: 0.9807 - val_loss: 0.1191 - val_categorical_accuracy: 0.9867\n",
      "Epoch 252/10000\n",
      "254/254 [==============================] - 7s 29ms/step - loss: 0.1335 - categorical_accuracy: 0.9813 - val_loss: 0.1193 - val_categorical_accuracy: 0.9866\n",
      "Epoch 253/10000\n",
      "254/254 [==============================] - 7s 29ms/step - loss: 0.1335 - categorical_accuracy: 0.9807 - val_loss: 0.1185 - val_categorical_accuracy: 0.9865\n",
      "Epoch 254/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.1328 - categorical_accuracy: 0.9814 - val_loss: 0.1191 - val_categorical_accuracy: 0.9865\n",
      "Epoch 255/10000\n",
      "254/254 [==============================] - 7s 29ms/step - loss: 0.1334 - categorical_accuracy: 0.9802 - val_loss: 0.1182 - val_categorical_accuracy: 0.9867\n",
      "Epoch 256/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.1337 - categorical_accuracy: 0.9807 - val_loss: 0.1182 - val_categorical_accuracy: 0.9870\n",
      "Epoch 257/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.1320 - categorical_accuracy: 0.9817 - val_loss: 0.1187 - val_categorical_accuracy: 0.9869\n",
      "Epoch 258/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.1337 - categorical_accuracy: 0.9810 - val_loss: 0.1200 - val_categorical_accuracy: 0.9863\n",
      "Epoch 259/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.1314 - categorical_accuracy: 0.9812 - val_loss: 0.1172 - val_categorical_accuracy: 0.9871\n",
      "Epoch 260/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.1308 - categorical_accuracy: 0.9815 - val_loss: 0.1186 - val_categorical_accuracy: 0.9865\n",
      "Epoch 261/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.1319 - categorical_accuracy: 0.9808 - val_loss: 0.1186 - val_categorical_accuracy: 0.9867\n",
      "Epoch 262/10000\n",
      "254/254 [==============================] - 8s 32ms/step - loss: 0.1297 - categorical_accuracy: 0.9817 - val_loss: 0.1169 - val_categorical_accuracy: 0.9870\n",
      "Epoch 263/10000\n",
      "254/254 [==============================] - 7s 29ms/step - loss: 0.1302 - categorical_accuracy: 0.9813 - val_loss: 0.1189 - val_categorical_accuracy: 0.9868\n",
      "Epoch 264/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.1302 - categorical_accuracy: 0.9810 - val_loss: 0.1184 - val_categorical_accuracy: 0.9867\n",
      "Epoch 265/10000\n",
      "254/254 [==============================] - 8s 30ms/step - loss: 0.1308 - categorical_accuracy: 0.9812 - val_loss: 0.1177 - val_categorical_accuracy: 0.9861\n",
      "Epoch 266/10000\n",
      "254/254 [==============================] - 8s 30ms/step - loss: 0.1305 - categorical_accuracy: 0.9812 - val_loss: 0.1166 - val_categorical_accuracy: 0.9868\n",
      "Epoch 267/10000\n",
      "254/254 [==============================] - 6s 26ms/step - loss: 0.1312 - categorical_accuracy: 0.9809 - val_loss: 0.1169 - val_categorical_accuracy: 0.9869\n",
      "Epoch 268/10000\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 0.1305 - categorical_accuracy: 0.9810 - val_loss: 0.1164 - val_categorical_accuracy: 0.9868\n",
      "Epoch 269/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.1294 - categorical_accuracy: 0.9812 - val_loss: 0.1171 - val_categorical_accuracy: 0.9866\n",
      "Epoch 270/10000\n",
      "254/254 [==============================] - 7s 29ms/step - loss: 0.1288 - categorical_accuracy: 0.9818 - val_loss: 0.1170 - val_categorical_accuracy: 0.9861\n",
      "Epoch 271/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.1284 - categorical_accuracy: 0.9816 - val_loss: 0.1167 - val_categorical_accuracy: 0.9865\n",
      "Epoch 272/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.1275 - categorical_accuracy: 0.9816 - val_loss: 0.1162 - val_categorical_accuracy: 0.9865\n",
      "Epoch 273/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.1289 - categorical_accuracy: 0.9811 - val_loss: 0.1157 - val_categorical_accuracy: 0.9864\n",
      "Epoch 274/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.1277 - categorical_accuracy: 0.9813 - val_loss: 0.1151 - val_categorical_accuracy: 0.9868\n",
      "Epoch 275/10000\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.1280 - categorical_accuracy: 0.9814 - val_loss: 0.1143 - val_categorical_accuracy: 0.9872\n",
      "Epoch 276/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.1279 - categorical_accuracy: 0.9811 - val_loss: 0.1163 - val_categorical_accuracy: 0.9863\n",
      "Epoch 277/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.1276 - categorical_accuracy: 0.9816 - val_loss: 0.1145 - val_categorical_accuracy: 0.9866\n",
      "Epoch 278/10000\n",
      "254/254 [==============================] - 8s 31ms/step - loss: 0.1264 - categorical_accuracy: 0.9817 - val_loss: 0.1139 - val_categorical_accuracy: 0.9866\n",
      "Epoch 279/10000\n",
      "254/254 [==============================] - 8s 31ms/step - loss: 0.1281 - categorical_accuracy: 0.9811 - val_loss: 0.1146 - val_categorical_accuracy: 0.9869\n",
      "Epoch 280/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.1277 - categorical_accuracy: 0.9810 - val_loss: 0.1137 - val_categorical_accuracy: 0.9864\n",
      "Epoch 281/10000\n",
      "254/254 [==============================] - 7s 29ms/step - loss: 0.1279 - categorical_accuracy: 0.9809 - val_loss: 0.1121 - val_categorical_accuracy: 0.9868\n",
      "Epoch 282/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.1274 - categorical_accuracy: 0.9814 - val_loss: 0.1122 - val_categorical_accuracy: 0.9857\n",
      "Epoch 283/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.1254 - categorical_accuracy: 0.9816 - val_loss: 0.1117 - val_categorical_accuracy: 0.9869\n",
      "Epoch 284/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254/254 [==============================] - 7s 28ms/step - loss: 0.1254 - categorical_accuracy: 0.9822 - val_loss: 0.1105 - val_categorical_accuracy: 0.9871\n",
      "Epoch 285/10000\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.1265 - categorical_accuracy: 0.9810 - val_loss: 0.1117 - val_categorical_accuracy: 0.9866\n",
      "Epoch 286/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.1253 - categorical_accuracy: 0.9815 - val_loss: 0.1103 - val_categorical_accuracy: 0.9868\n",
      "Epoch 287/10000\n",
      "254/254 [==============================] - 8s 30ms/step - loss: 0.1243 - categorical_accuracy: 0.9820 - val_loss: 0.1111 - val_categorical_accuracy: 0.9867\n",
      "Epoch 288/10000\n",
      "254/254 [==============================] - 7s 28ms/step - loss: 0.1255 - categorical_accuracy: 0.9819 - val_loss: 0.1109 - val_categorical_accuracy: 0.9866\n",
      "Epoch 289/10000\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 0.1244 - categorical_accuracy: 0.9816 - val_loss: 0.1113 - val_categorical_accuracy: 0.9865\n",
      "Epoch 290/10000\n",
      "254/254 [==============================] - 7s 29ms/step - loss: 0.1242 - categorical_accuracy: 0.9816 - val_loss: 0.1112 - val_categorical_accuracy: 0.9871\n",
      "Epoch 291/10000\n",
      "254/254 [==============================] - 7s 29ms/step - loss: 0.1229 - categorical_accuracy: 0.9821 - val_loss: 0.1127 - val_categorical_accuracy: 0.9865\n",
      "Trained and saved new model.\n",
      "Finished at 2022-10-15 17:37:43.875068, took 0:33:27.076507 seconds\n"
     ]
    }
   ],
   "source": [
    "model = SherlockModel()\n",
    "try:\n",
    "    model.initialize_model_from_json(with_weights=True, model_id=model_id);\n",
    "except:\n",
    "    start = datetime.now()\n",
    "    print(f'Started at {start}')\n",
    "    # Model will be stored with ID `model_id`\n",
    "    model.fit(X_train, y_train, X_validation, y_validation, model_id=model_id)\n",
    "\n",
    "    print('Trained and saved new model.')\n",
    "    print(f'Finished at {datetime.now()}, took {datetime.now() - start} seconds')\n",
    "    model.store_weights(model_id=model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1015 17:37:45.789397 46912499975424 ag_logging.py:142] AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x2aacf7f0c4c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x2aacf7f0c4c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = model.predict(X_test, model_id)\n",
    "predicted_labels = np.array([x.lower() for x in predicted_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction count 65007, type = <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9865786464428956"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'prediction count {len(predicted_labels)}, type = {type(predicted_labels)}')\n",
    "\n",
    "size=len(y_test)\n",
    "\n",
    "# Should be fully deterministic too.\n",
    "f1_score(y_test[:size], predicted_labels[:size], average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using the original model, model_id should be replaced with \"sherlock\"\n",
    "#model_id = \"sherlock\"\n",
    "classes = np.load(f\"../model_files/classes_{model_id}.npy\", allow_pickle=True)\n",
    "\n",
    "report = classification_report(y_test, predicted_labels, output_dict=True)\n",
    "\n",
    "class_scores = list(filter(lambda x: isinstance(x, tuple) and isinstance(x[1], dict) and 'f1-score' in x[1] and x[0] in classes, list(report.items())))\n",
    "\n",
    "class_scores = sorted(class_scores, key=lambda item: item[1]['f1-score'], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 5 Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tf1-score\tprecision\trecall\t\tsupport\n",
      "industry\t0.999\t\t1.000\t\t0.999\t\t2958\n",
      "manufacturer\t0.998\t\t1.000\t\t0.997\t\t945\n",
      "product\t\t0.998\t\t1.000\t\t0.997\t\t2647\n",
      "birth date\t0.998\t\t1.000\t\t0.996\t\t479\n",
      "birth place\t0.998\t\t0.998\t\t0.998\t\t418\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\t\\tf1-score\\tprecision\\trecall\\t\\tsupport\")\n",
    "\n",
    "for key, value in class_scores[0:5]:\n",
    "    if len(key) >= 8:\n",
    "        tabs = '\\t' * 1\n",
    "    else:\n",
    "        tabs = '\\t' * 2\n",
    "\n",
    "    print(f\"{key}{tabs}{value['f1-score']:.3f}\\t\\t{value['precision']:.3f}\\t\\t{value['recall']:.3f}\\t\\t{value['support']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bottom 5 Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tf1-score\tprecision\trecall\t\tsupport\n",
      "sales\t\t0.976\t\t0.994\t\t0.960\t\t322\n",
      "status\t\t0.972\t\t0.950\t\t0.996\t\t3100\n",
      "day\t\t0.959\t\t0.965\t\t0.954\t\t3038\n",
      "rank\t\t0.924\t\t0.925\t\t0.923\t\t2983\n",
      "order\t\t0.910\t\t0.895\t\t0.925\t\t1462\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\t\\tf1-score\\tprecision\\trecall\\t\\tsupport\")\n",
    "\n",
    "for key, value in class_scores[len(class_scores)-5:len(class_scores)]:\n",
    "    if len(key) >= 8:\n",
    "        tabs = '\\t' * 1\n",
    "    else:\n",
    "        tabs = '\\t' * 2\n",
    "\n",
    "    print(f\"{key}{tabs}{value['f1-score']:.3f}\\t\\t{value['precision']:.3f}\\t\\t{value['recall']:.3f}\\t\\t{value['support']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     address      0.998     0.994     0.996      3003\n",
      "         age      0.987     0.995     0.991      3033\n",
      "        area      0.998     0.988     0.993      1987\n",
      "  birth date      1.000     0.996     0.998       479\n",
      " birth place      0.998     0.998     0.998       418\n",
      "       brand      1.000     0.981     0.990       574\n",
      "        city      0.999     0.996     0.997      2966\n",
      "   continent      0.996     0.978     0.987       227\n",
      "     country      0.997     0.996     0.997      3038\n",
      "      county      0.997     0.995     0.996      2959\n",
      "    currency      0.993     0.995     0.994       405\n",
      "         day      0.965     0.954     0.959      3038\n",
      "    duration      0.996     0.998     0.997      3000\n",
      "    industry      1.000     0.999     0.999      2958\n",
      "    language      0.984     0.981     0.982      1474\n",
      "    location      1.000     0.993     0.996      2949\n",
      "manufacturer      1.000     0.997     0.998       945\n",
      "        name      0.996     0.997     0.997      3017\n",
      " nationality      0.998     0.993     0.995       424\n",
      "       order      0.895     0.925     0.910      1462\n",
      "      person      1.000     0.965     0.982       579\n",
      "     product      1.000     0.997     0.998      2647\n",
      "       range      0.995     0.988     0.991       577\n",
      "        rank      0.925     0.923     0.924      2983\n",
      "      region      0.995     0.976     0.985      2740\n",
      "       sales      0.994     0.960     0.976       322\n",
      "         sex      0.991     0.997     0.994      2997\n",
      "       state      0.998     0.994     0.996      3030\n",
      "      status      0.950     0.996     0.972      3100\n",
      "      symbol      0.989     0.998     0.993      1752\n",
      "        type      0.992     0.990     0.991      2909\n",
      "        year      0.999     0.994     0.997      3015\n",
      "\n",
      "    accuracy                          0.987     65007\n",
      "   macro avg      0.988     0.985     0.987     65007\n",
      "weighted avg      0.987     0.987     0.987     65007\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predicted_labels, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9920] expected \"address\" but predicted \"status\"\n",
      "[14477] expected \"address\" but predicted \"status\"\n",
      "[15145] expected \"address\" but predicted \"status\"\n",
      "[17047] expected \"address\" but predicted \"type\"\n",
      "[17689] expected \"address\" but predicted \"status\"\n",
      "[17788] expected \"address\" but predicted \"status\"\n",
      "[19063] expected \"address\" but predicted \"status\"\n",
      "[22419] expected \"address\" but predicted \"status\"\n",
      "[28573] expected \"address\" but predicted \"status\"\n",
      "[29339] expected \"address\" but predicted \"status\"\n",
      "[35994] expected \"address\" but predicted \"status\"\n",
      "[36306] expected \"address\" but predicted \"type\"\n",
      "[40584] expected \"address\" but predicted \"type\"\n",
      "[40677] expected \"address\" but predicted \"type\"\n",
      "[48830] expected \"address\" but predicted \"status\"\n",
      "[56111] expected \"address\" but predicted \"status\"\n",
      "[57986] expected \"address\" but predicted \"type\"\n",
      "[64711] expected \"address\" but predicted \"status\"\n",
      "Total mismatches: 875 (F1 score: 0.9865786464428956)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('rank', 230),\n",
       " ('day', 141),\n",
       " ('order', 109),\n",
       " ('region', 67),\n",
       " ('type', 29),\n",
       " ('language', 28),\n",
       " ('area', 23),\n",
       " ('location', 21),\n",
       " ('person', 20),\n",
       " ('year', 18),\n",
       " ('address', 18),\n",
       " ('state', 17),\n",
       " ('age', 16),\n",
       " ('county', 14),\n",
       " ('city', 13),\n",
       " ('sales', 13),\n",
       " ('status', 13),\n",
       " ('country', 12),\n",
       " ('brand', 11),\n",
       " ('sex', 10),\n",
       " ('product', 9),\n",
       " ('name', 9),\n",
       " ('range', 7),\n",
       " ('duration', 5),\n",
       " ('continent', 5),\n",
       " ('symbol', 4),\n",
       " ('manufacturer', 3),\n",
       " ('nationality', 3),\n",
       " ('birth date', 2),\n",
       " ('currency', 2),\n",
       " ('industry', 2),\n",
       " ('birth place', 1)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = len(y_test)\n",
    "mismatches = list()\n",
    "\n",
    "for idx, k1 in enumerate(y_test[:size]):\n",
    "    k2 = predicted_labels[idx]\n",
    "\n",
    "    if k1 != k2:\n",
    "        mismatches.append(k1)\n",
    "        \n",
    "        # zoom in to specific errors. Use the index in the next step\n",
    "        if k1 in ('address'):\n",
    "            print(f'[{idx}] expected \"{k1}\" but predicted \"{k2}\"')\n",
    "        \n",
    "f1 = f1_score(y_test[:size], predicted_labels[:size], average=\"weighted\")\n",
    "print(f'Total mismatches: {len(mismatches)} (F1 score: {f1})')\n",
    "\n",
    "data = Counter(mismatches)\n",
    "data.most_common()   # Returns all unique items and their counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = pd.read_parquet('../data/data/raw/test_values.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted \"symbol\", actual label \"symbol\". Actual values:\n",
      "[['VASC', 'TNK', 'NAT', 'GPRO', 'MANH']]\n"
     ]
    }
   ],
   "source": [
    "idx = 57\n",
    "\n",
    "\n",
    "original = test_samples.iloc[idx]\n",
    "converted = original.apply(literal_eval).to_list()\n",
    "\n",
    "print(f'Predicted \"{predicted_labels[idx]}\", actual label \"{y_test[idx]}\". Actual values:\\n{converted}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "dbbef01d25d9fb4d9430fa9d81ea780e18a1c669119e240c1440cbb3ef3d3f19"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
