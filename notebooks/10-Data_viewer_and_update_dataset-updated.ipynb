{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a48f0266",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import load\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import requests\n",
    "from io import StringIO\n",
    "import pyarrow.parquet as pq\n",
    "from urllib.error import HTTPError\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "681ed090",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = load('classes_sherlock.npy', allow_pickle=True)\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a66ee59",
   "metadata": {},
   "outputs": [],
   "source": [
    "acceptable_columns = ['address', 'age', 'area', 'birth Date', 'birth Place', 'brand', 'city', 'continent', 'country', 'county', 'currency', 'day', 'duration', 'industry', 'language', 'location', 'manufacturer', 'name', 'nationality', 'order', 'person', 'product', 'range', 'rank', 'region','sales', 'sex', 'state', 'status', 'symbol', 'type', 'year']\n",
    "acceptable_columns = np.array(acceptable_columns)\n",
    "# np.save(\"classes_sherlock.npy\", acceptable_columns, allow_pickle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a73ed667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main dataframes to add onto existing dataframe\n",
    "new_train = pd.DataFrame(columns = ['type', 'values'])\n",
    "new_test = pd.DataFrame(columns = ['type', 'values'])\n",
    "new_val = pd.DataFrame(columns = ['type', 'values'])\n",
    "\n",
    "# list of urls of csvs\n",
    "urls = ['https://drive.google.com/file/d/1JPdeXZ5h6zM_esbpUwlpVD-hFx7ifVmm/view?usp=sharing', 'https://drive.google.com/file/d/10eD7XzIql6LOVJlW9C7Wzc1DVnECigBw/view?usp=sharing',\n",
    "        'https://drive.google.com/file/d/1IfQ5SAPgdX8R84qvWxAIy-XoMGC4EuNW/view?usp=sharing','https://drive.google.com/file/d/1bHYZGXgYP7PYWrNFvpXGJXKJNgZxhyBU/view?usp=sharing']\n",
    "# list of types\n",
    "types = ['guuid','guuid','tax_id','social_security']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b65b8fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through all urls\n",
    "for i in range(len(urls)):\n",
    "    url = urls[i]\n",
    "    #check that url is valid\n",
    "    try:\n",
    "        file_id = url.split('/')[-2]\n",
    "        dwn_url='https://drive.google.com/uc?id=' + file_id\n",
    "        #check that data is csv\n",
    "        try:\n",
    "            data = pd.read_csv(dwn_url, sep=\";\", header=None)\n",
    "            t = types[i]\n",
    "            #check that data is single column\n",
    "            if data.shape[1] != 1:\n",
    "                print('Data is not a single column')\n",
    "                continue\n",
    "        except UnicodeDecodeError:\n",
    "            print('Data not in csv format')\n",
    "            continue\n",
    "    except HTTPError:\n",
    "        print('Error: Link '+ url + ' not valid')\n",
    "        continue\n",
    "    \n",
    "    # split 0.8 to training, 0.1 to test, and 0.1 to validation\n",
    "    train_idx = round(len(data)*0.8)\n",
    "    test_idx = round(len(data)*0.15)\n",
    "    train_data = data.iloc[:train_idx]\n",
    "    test_data = data.iloc[train_idx: (train_idx+test_idx)]\n",
    "    val_data = data.iloc[(train_idx+test_idx):]\n",
    "\n",
    "    # splitting into chunks of ~five data points\n",
    "    train_data = train_data.values.tolist()\n",
    "    #split data from list\n",
    "    train_data = list(itertools.chain(*train_data))\n",
    "    splitval = train_idx/5\n",
    "    train_data = [str(i) for i in train_data]\n",
    "    #split into 5 seperate arrays\n",
    "    train_data_split = np.array_split(train_data, splitval)\n",
    "    #gather arrays into dataframe\n",
    "    train_df = pd.Series(train_data_split, name='values').to_frame()\n",
    "    #set train_df['type'] to current type\n",
    "    train_df['type'] = t\n",
    "    #convert all train_df['values'] to string\n",
    "    train_df = train_df.iloc[:,[1,0]]\n",
    "    train_df['values'] = [str(i) for i in train_df['values']]\n",
    "\n",
    "    #repeat above for test_data\n",
    "    splitval = round(test_idx/5)\n",
    "    test_data = test_data.values.tolist()\n",
    "    test_data = list(itertools.chain(*test_data))\n",
    "    test_data = [str(i) for i in test_data]\n",
    "    test_data_split = np.array_split(test_data, splitval)\n",
    "    test_df = pd.Series(test_data_split, name='values').to_frame()\n",
    "    test_df['type'] = t\n",
    "    test_df = test_df.iloc[:,[1,0]]\n",
    "    test_df['values'] = [str(i) for i in test_df['values']]\n",
    "\n",
    "    #repeat above for validation_data\n",
    "    splitval = round(len(val_data)/5)\n",
    "    val_data = val_data.values.tolist()\n",
    "    val_data = list(itertools.chain(*val_data))\n",
    "    val_data = [str(i) for i in val_data]\n",
    "    val_data_split = np.array_split(val_data, splitval)\n",
    "    val_df = pd.Series(val_data_split, name='values').to_frame()\n",
    "    val_df['type'] = t\n",
    "    val_df = val_df.iloc[:,[1,0]] \n",
    "    val_df['values'] = [str(i) for i in val_df['values']]\n",
    "    \n",
    "    #remove warnings for append dataframe\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    # add to main dataframes\n",
    "    new_train = new_train.append(train_df, ignore_index=True)\n",
    "    new_test = new_test.append(test_df, ignore_index=True)\n",
    "    new_val = new_val.append(val_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b95952bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read current train values and labels\n",
    "train_df_values = pq.read_table(source=\"./data/raw/train_values.parquet\").to_pandas()\n",
    "train_df_labels = pq.read_table(source=\"./data/raw/train_labels.parquet\").to_pandas()\n",
    "#create new dataframe of current values and labels\n",
    "train_df_full = train_df_labels.merge(train_df_values, left_index=True, right_index=True)\n",
    "train_df_full = train_df_full[train_df_full['type'].isin(acceptable_columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc130680",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up old dataframe format\n",
    "old_train = pd.DataFrame(columns = ['type', 'values'])\n",
    "old_test = pd.DataFrame(columns = ['type', 'values'])\n",
    "old_val = pd.DataFrame(columns = ['type', 'values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d85efdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split each semantic type in original Sherlock data into 0.8 for training, 0.15 for testing, 0.05 for validation\n",
    "for i in range(len(acceptable_columns)):\n",
    "    temp_df = train_df_full[train_df_full[\"type\"] == acceptable_columns[i]]\n",
    "    training_idx = round(len(temp_df)*0.8)\n",
    "    testing_idx = round(len(temp_df)*0.15)\n",
    "    training_data = temp_df.iloc[:training_idx]\n",
    "    testing_data = temp_df.iloc[training_idx: (training_idx+testing_idx)]\n",
    "    valid_data = temp_df.iloc[(training_idx+testing_idx):]\n",
    "    \n",
    "    old_train = old_train.append(training_data, ignore_index=True)\n",
    "    old_test = old_test.append(testing_data, ignore_index=True)\n",
    "    old_val = old_val.append(valid_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e61d0cd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#append old test data to new test data\n",
    "test_df_full = old_test.append(new_test, ignore_index=True)\n",
    "test_df_values = pd.DataFrame(test_df_full, columns=['values'])\n",
    "test_df_labels = pd.DataFrame(test_df_full, columns=['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6952b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#append old train data to new train data\n",
    "train_df_full = old_train.append(new_train, ignore_index=True)\n",
    "train_df_values = pd.DataFrame(train_df_full, columns=['values'])\n",
    "train_df_labels = pd.DataFrame(train_df_full, columns=['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c9a5672",
   "metadata": {},
   "outputs": [],
   "source": [
    "#append old validation data to new validation data\n",
    "val_df_full = old_val.append(new_val, ignore_index=True)\n",
    "val_df_values = pd.DataFrame(val_df_full, columns=['values'])\n",
    "val_df_labels = pd.DataFrame(val_df_full, columns=['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb3a4693",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save test,train,and validation labels to data folder\n",
    "test_df_labels.to_parquet(\"./data/raw/test_labels.parquet\", engine='fastparquet')\n",
    "test_df_values.to_parquet(\"./data/raw/test_values.parquet\", engine='fastparquet')\n",
    "\n",
    "train_df_labels.to_parquet(\"./data/raw/train_labels.parquet\", engine='fastparquet')\n",
    "train_df_values.to_parquet(\"./data/raw/train_values.parquet\", engine='fastparquet')\n",
    "\n",
    "val_df_labels.to_parquet(\"./data/raw/val_labels.parquet\", engine='fastparquet')\n",
    "val_df_values.to_parquet(\"./data/raw/val_values.parquet\", engine='fastparquet')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3c5f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO:\n",
    "# add a try catch for putting in an unvalid link ~\n",
    "# also maybe a try catch for if the data is not in the right format (i.e. not in a csv with a single column) ~\n",
    "# get rid of any unnecessary code  \n",
    "# hide warnings so the warning about append won't show up or change the code to use concat instead\n",
    "# add any extra comments to make the code more readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59b6764",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "19d762ffc7d2f958e0963c75da0d959adf181f4ac62524ed3e80179df28269f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
