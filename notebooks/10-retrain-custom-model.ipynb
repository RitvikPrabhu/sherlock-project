{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook enables training and testing of Sherlock.\n",
    "The procedure is:\n",
    "- Load train, val, test datasets (should be preprocessed)\n",
    "- Initialize model using the \"pretrained\" model or by training one from scratch.\n",
    "- Evaluate and analyse the model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTHONHASHSEED=13\n"
     ]
    }
   ],
   "source": [
    "%env PYTHONHASHSEED=13\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will be the ID for the retrained model,\n",
    "#further down predictions can also be made with the original model: \"sherlock\"\n",
    "model_id = 'retrained_sherlock'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "from sherlock.deploy.model import SherlockModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets for training, validation, testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2022-10-15 16:21:04.731660\n",
      "Load data (train) process took 0:00:01.655188 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "print(f'Started at {start}')\n",
    "\n",
    "X_train = pd.read_parquet('../data/data/processed/train.parquet')\n",
    "y_train = pd.read_parquet('../data/data/raw/train_labels.parquet').values.flatten()\n",
    "\n",
    "y_train = np.array([x.lower() for x in y_train])\n",
    "\n",
    "print(f'Load data (train) process took {datetime.now() - start} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct types for columns in the Dataframe (should be all float32):\n",
      "{dtype('float32')}\n"
     ]
    }
   ],
   "source": [
    "print('Distinct types for columns in the Dataframe (should be all float32):')\n",
    "print(set(X_train.dtypes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2022-10-15 16:21:06.697384\n",
      "Load data (validation) process took 0:00:01.013941 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "print(f'Started at {start}')\n",
    "\n",
    "X_validation = pd.read_parquet('../data/data/processed/validation.parquet')\n",
    "y_validation = pd.read_parquet('../data/data/raw/val_labels.parquet').values.flatten()\n",
    "\n",
    "y_validation = np.array([x.lower() for x in y_validation])\n",
    "\n",
    "print(f'Load data (validation) process took {datetime.now() - start} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2022-10-15 16:21:07.766820\n",
      "Finished at 2022-10-15 16:21:09.039885, took 0:00:01.273078 seconds\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "print(f'Started at {start}')\n",
    "\n",
    "X_test = pd.read_parquet('../data/data/processed/test.parquet')\n",
    "y_test = pd.read_parquet('../data/data/raw/test_labels.parquet').values.flatten()\n",
    "\n",
    "y_test = np.array([x.lower() for x in y_test])\n",
    "\n",
    "print(f'Finished at {datetime.now()}, took {datetime.now() - start} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the model\n",
    "Two options:\n",
    "- Load Sherlock model with pretrained weights\n",
    "- Fit Sherlock model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"retrained_sherlock\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2022-10-15 16:21:09.111457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-15 16:21:09.335083: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-15 16:21:09.338257: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "/home/ritvikp/.conda/envs/myenv3.8/lib/python3.8/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1015 16:21:10.187919 46912499975424 ag_logging.py:142] AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x2aab4b9a0940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x2aab4b9a0940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "252/254 [============================>.] - ETA: 0s - loss: 2.0015 - categorical_accuracy: 0.5757"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1015 16:21:16.402033 46912499975424 ag_logging.py:142] AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x2aad5577ddc0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x2aad5577ddc0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "254/254 [==============================] - 8s 27ms/step - loss: 1.9964 - categorical_accuracy: 0.5768 - val_loss: 1.3487 - val_categorical_accuracy: 0.7508\n",
      "Epoch 2/10\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 1.1410 - categorical_accuracy: 0.7805 - val_loss: 0.8867 - val_categorical_accuracy: 0.8444\n",
      "Epoch 3/10\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.9753 - categorical_accuracy: 0.8195 - val_loss: 0.7946 - val_categorical_accuracy: 0.8667\n",
      "Epoch 4/10\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 0.8961 - categorical_accuracy: 0.8388 - val_loss: 0.7437 - val_categorical_accuracy: 0.8807\n",
      "Epoch 5/10\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 0.8485 - categorical_accuracy: 0.8510 - val_loss: 0.7064 - val_categorical_accuracy: 0.8884\n",
      "Epoch 6/10\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.8100 - categorical_accuracy: 0.8609 - val_loss: 0.6767 - val_categorical_accuracy: 0.8954\n",
      "Epoch 7/10\n",
      "254/254 [==============================] - 6s 24ms/step - loss: 0.7738 - categorical_accuracy: 0.8693 - val_loss: 0.6535 - val_categorical_accuracy: 0.9006\n",
      "Epoch 8/10\n",
      "254/254 [==============================] - 6s 25ms/step - loss: 0.7491 - categorical_accuracy: 0.8749 - val_loss: 0.6323 - val_categorical_accuracy: 0.9059\n",
      "Epoch 9/10\n",
      "254/254 [==============================] - 7s 26ms/step - loss: 0.7222 - categorical_accuracy: 0.8814 - val_loss: 0.6121 - val_categorical_accuracy: 0.9089\n",
      "Epoch 10/10\n",
      "254/254 [==============================] - 7s 27ms/step - loss: 0.7035 - categorical_accuracy: 0.8843 - val_loss: 0.5961 - val_categorical_accuracy: 0.9137\n",
      "Trained and saved new model.\n",
      "Finished at 2022-10-15 16:22:17.242551, took 0:01:08.131111 seconds\n"
     ]
    }
   ],
   "source": [
    "model = SherlockModel()\n",
    "try:\n",
    "    model.initialize_model_from_json(with_weights=True, model_id=model_id);\n",
    "except:\n",
    "    start = datetime.now()\n",
    "    print(f'Started at {start}')\n",
    "    # Model will be stored with ID `model_id`\n",
    "    model.fit(X_train, y_train, X_validation, y_validation, model_id=model_id)\n",
    "\n",
    "    print('Trained and saved new model.')\n",
    "    print(f'Finished at {datetime.now()}, took {datetime.now() - start} seconds')\n",
    "    model.store_weights(model_id=model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1015 16:22:19.045528 46912499975424 ag_logging.py:142] AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x2aad5577dd30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x2aad5577dd30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = model.predict(X_test, model_id)\n",
    "predicted_labels = np.array([x.lower() for x in predicted_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction count 65007, type = <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9129910873635969"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'prediction count {len(predicted_labels)}, type = {type(predicted_labels)}')\n",
    "\n",
    "size=len(y_test)\n",
    "\n",
    "# Should be fully deterministic too.\n",
    "f1_score(y_test[:size], predicted_labels[:size], average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using the original model, model_id should be replaced with \"sherlock\"\n",
    "#model_id = \"sherlock\"\n",
    "classes = np.load(f\"../model_files/classes_{model_id}.npy\", allow_pickle=True)\n",
    "\n",
    "report = classification_report(y_test, predicted_labels, output_dict=True)\n",
    "\n",
    "class_scores = list(filter(lambda x: isinstance(x, tuple) and isinstance(x[1], dict) and 'f1-score' in x[1] and x[0] in classes, list(report.items())))\n",
    "\n",
    "class_scores = sorted(class_scores, key=lambda item: item[1]['f1-score'], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 5 Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tf1-score\tprecision\trecall\t\tsupport\n",
      "industry\t0.985\t\t0.983\t\t0.987\t\t2958\n",
      "birth date\t0.979\t\t0.975\t\t0.983\t\t479\n",
      "sex\t\t0.974\t\t0.982\t\t0.966\t\t2997\n",
      "currency\t0.968\t\t0.975\t\t0.960\t\t405\n",
      "year\t\t0.964\t\t0.977\t\t0.951\t\t3015\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\t\\tf1-score\\tprecision\\trecall\\t\\tsupport\")\n",
    "\n",
    "for key, value in class_scores[0:5]:\n",
    "    if len(key) >= 8:\n",
    "        tabs = '\\t' * 1\n",
    "    else:\n",
    "        tabs = '\\t' * 2\n",
    "\n",
    "    print(f\"{key}{tabs}{value['f1-score']:.3f}\\t\\t{value['precision']:.3f}\\t\\t{value['recall']:.3f}\\t\\t{value['support']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bottom 5 Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tf1-score\tprecision\trecall\t\tsupport\n",
      "range\t\t0.799\t\t0.902\t\t0.718\t\t577\n",
      "nationality\t0.769\t\t0.786\t\t0.752\t\t424\n",
      "rank\t\t0.755\t\t0.661\t\t0.881\t\t2983\n",
      "person\t\t0.701\t\t0.912\t\t0.570\t\t579\n",
      "sales\t\t0.341\t\t0.795\t\t0.217\t\t322\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\t\\tf1-score\\tprecision\\trecall\\t\\tsupport\")\n",
    "\n",
    "for key, value in class_scores[len(class_scores)-5:len(class_scores)]:\n",
    "    if len(key) >= 8:\n",
    "        tabs = '\\t' * 1\n",
    "    else:\n",
    "        tabs = '\\t' * 2\n",
    "\n",
    "    print(f\"{key}{tabs}{value['f1-score']:.3f}\\t\\t{value['precision']:.3f}\\t\\t{value['recall']:.3f}\\t\\t{value['support']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     address      0.955     0.967     0.961      3003\n",
      "         age      0.886     0.964     0.923      3033\n",
      "        area      0.959     0.798     0.871      1987\n",
      "  birth date      0.975     0.983     0.979       479\n",
      " birth place      0.995     0.933     0.963       418\n",
      "       brand      0.875     0.768     0.818       574\n",
      "        city      0.852     0.943     0.895      2966\n",
      "   continent      0.794     0.934     0.858       227\n",
      "     country      0.919     0.949     0.934      3038\n",
      "      county      0.961     0.953     0.957      2959\n",
      "    currency      0.975     0.960     0.968       405\n",
      "         day      0.915     0.878     0.896      3038\n",
      "    duration      0.951     0.943     0.947      3000\n",
      "    industry      0.983     0.987     0.985      2958\n",
      "    language      0.852     0.967     0.906      1474\n",
      "    location      0.943     0.825     0.880      2949\n",
      "manufacturer      0.928     0.892     0.910       945\n",
      "        name      0.866     0.912     0.889      3017\n",
      " nationality      0.786     0.752     0.769       424\n",
      "       order      0.960     0.828     0.889      1462\n",
      "      person      0.912     0.570     0.701       579\n",
      "     product      0.914     0.940     0.927      2647\n",
      "       range      0.902     0.718     0.799       577\n",
      "        rank      0.661     0.881     0.755      2983\n",
      "      region      0.929     0.798     0.859      2740\n",
      "       sales      0.795     0.217     0.341       322\n",
      "         sex      0.982     0.966     0.974      2997\n",
      "       state      0.934     0.970     0.952      3030\n",
      "      status      0.963     0.957     0.960      3100\n",
      "      symbol      0.953     0.974     0.963      1752\n",
      "        type      0.931     0.923     0.927      2909\n",
      "        year      0.977     0.951     0.964      3015\n",
      "\n",
      "    accuracy                          0.914     65007\n",
      "   macro avg      0.912     0.875     0.885     65007\n",
      "weighted avg      0.919     0.914     0.913     65007\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predicted_labels, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1201] expected \"address\" but predicted \"city\"\n",
      "[1585] expected \"address\" but predicted \"city\"\n",
      "[2256] expected \"address\" but predicted \"name\"\n",
      "[2303] expected \"address\" but predicted \"rank\"\n",
      "[3342] expected \"address\" but predicted \"name\"\n",
      "[4640] expected \"address\" but predicted \"city\"\n",
      "[4787] expected \"address\" but predicted \"rank\"\n",
      "[5261] expected \"address\" but predicted \"city\"\n",
      "[5729] expected \"address\" but predicted \"location\"\n",
      "[7390] expected \"address\" but predicted \"location\"\n",
      "[7404] expected \"address\" but predicted \"city\"\n",
      "[9532] expected \"address\" but predicted \"city\"\n",
      "[9920] expected \"address\" but predicted \"language\"\n",
      "[10188] expected \"address\" but predicted \"product\"\n",
      "[11837] expected \"address\" but predicted \"rank\"\n",
      "[12829] expected \"address\" but predicted \"name\"\n",
      "[14477] expected \"address\" but predicted \"language\"\n",
      "[15140] expected \"address\" but predicted \"city\"\n",
      "[15145] expected \"address\" but predicted \"language\"\n",
      "[15481] expected \"address\" but predicted \"city\"\n",
      "[15525] expected \"address\" but predicted \"city\"\n",
      "[16143] expected \"address\" but predicted \"name\"\n",
      "[16543] expected \"address\" but predicted \"location\"\n",
      "[16821] expected \"address\" but predicted \"location\"\n",
      "[17047] expected \"address\" but predicted \"language\"\n",
      "[17088] expected \"address\" but predicted \"location\"\n",
      "[17689] expected \"address\" but predicted \"language\"\n",
      "[17747] expected \"address\" but predicted \"county\"\n",
      "[17788] expected \"address\" but predicted \"language\"\n",
      "[19063] expected \"address\" but predicted \"language\"\n",
      "[19185] expected \"address\" but predicted \"country\"\n",
      "[21290] expected \"address\" but predicted \"area\"\n",
      "[22018] expected \"address\" but predicted \"location\"\n",
      "[22419] expected \"address\" but predicted \"language\"\n",
      "[22532] expected \"address\" but predicted \"location\"\n",
      "[22631] expected \"address\" but predicted \"city\"\n",
      "[22678] expected \"address\" but predicted \"type\"\n",
      "[22787] expected \"address\" but predicted \"location\"\n",
      "[22911] expected \"address\" but predicted \"name\"\n",
      "[23876] expected \"address\" but predicted \"location\"\n",
      "[24509] expected \"address\" but predicted \"location\"\n",
      "[24818] expected \"address\" but predicted \"location\"\n",
      "[25623] expected \"address\" but predicted \"name\"\n",
      "[25742] expected \"address\" but predicted \"name\"\n",
      "[25753] expected \"address\" but predicted \"location\"\n",
      "[26579] expected \"address\" but predicted \"name\"\n",
      "[28218] expected \"address\" but predicted \"city\"\n",
      "[28333] expected \"address\" but predicted \"region\"\n",
      "[28573] expected \"address\" but predicted \"language\"\n",
      "[28663] expected \"address\" but predicted \"day\"\n",
      "[29339] expected \"address\" but predicted \"language\"\n",
      "[29636] expected \"address\" but predicted \"location\"\n",
      "[30714] expected \"address\" but predicted \"name\"\n",
      "[31830] expected \"address\" but predicted \"rank\"\n",
      "[33071] expected \"address\" but predicted \"city\"\n",
      "[33755] expected \"address\" but predicted \"location\"\n",
      "[34025] expected \"address\" but predicted \"city\"\n",
      "[34929] expected \"address\" but predicted \"sex\"\n",
      "[35213] expected \"address\" but predicted \"city\"\n",
      "[35994] expected \"address\" but predicted \"language\"\n",
      "[36306] expected \"address\" but predicted \"language\"\n",
      "[36869] expected \"address\" but predicted \"location\"\n",
      "[39210] expected \"address\" but predicted \"product\"\n",
      "[40218] expected \"address\" but predicted \"name\"\n",
      "[40324] expected \"address\" but predicted \"location\"\n",
      "[40391] expected \"address\" but predicted \"name\"\n",
      "[40584] expected \"address\" but predicted \"language\"\n",
      "[40677] expected \"address\" but predicted \"language\"\n",
      "[41137] expected \"address\" but predicted \"rank\"\n",
      "[41181] expected \"address\" but predicted \"product\"\n",
      "[41350] expected \"address\" but predicted \"product\"\n",
      "[42825] expected \"address\" but predicted \"location\"\n",
      "[42880] expected \"address\" but predicted \"city\"\n",
      "[43719] expected \"address\" but predicted \"location\"\n",
      "[44269] expected \"address\" but predicted \"country\"\n",
      "[45617] expected \"address\" but predicted \"location\"\n",
      "[45745] expected \"address\" but predicted \"product\"\n",
      "[46897] expected \"address\" but predicted \"status\"\n",
      "[46985] expected \"address\" but predicted \"location\"\n",
      "[47727] expected \"address\" but predicted \"symbol\"\n",
      "[48581] expected \"address\" but predicted \"location\"\n",
      "[48830] expected \"address\" but predicted \"language\"\n",
      "[51399] expected \"address\" but predicted \"rank\"\n",
      "[51787] expected \"address\" but predicted \"name\"\n",
      "[54105] expected \"address\" but predicted \"rank\"\n",
      "[54767] expected \"address\" but predicted \"range\"\n",
      "[55162] expected \"address\" but predicted \"county\"\n",
      "[56111] expected \"address\" but predicted \"language\"\n",
      "[57986] expected \"address\" but predicted \"language\"\n",
      "[58196] expected \"address\" but predicted \"rank\"\n",
      "[59662] expected \"address\" but predicted \"name\"\n",
      "[59806] expected \"address\" but predicted \"duration\"\n",
      "[60279] expected \"address\" but predicted \"product\"\n",
      "[60420] expected \"address\" but predicted \"rank\"\n",
      "[61914] expected \"address\" but predicted \"duration\"\n",
      "[62998] expected \"address\" but predicted \"location\"\n",
      "[64711] expected \"address\" but predicted \"status\"\n",
      "[64864] expected \"address\" but predicted \"location\"\n",
      "Total mismatches: 5611 (F1 score: 0.9129910873635969)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('region', 553),\n",
       " ('location', 515),\n",
       " ('area', 401),\n",
       " ('day', 372),\n",
       " ('rank', 355),\n",
       " ('name', 264),\n",
       " ('sales', 252),\n",
       " ('order', 251),\n",
       " ('person', 249),\n",
       " ('type', 224),\n",
       " ('duration', 172),\n",
       " ('city', 168),\n",
       " ('range', 163),\n",
       " ('product', 158),\n",
       " ('country', 155),\n",
       " ('year', 149),\n",
       " ('county', 140),\n",
       " ('status', 134),\n",
       " ('brand', 133),\n",
       " ('age', 108),\n",
       " ('nationality', 105),\n",
       " ('manufacturer', 102),\n",
       " ('sex', 102),\n",
       " ('address', 98),\n",
       " ('state', 90),\n",
       " ('language', 48),\n",
       " ('symbol', 45),\n",
       " ('industry', 38),\n",
       " ('birth place', 28),\n",
       " ('currency', 16),\n",
       " ('continent', 15),\n",
       " ('birth date', 8)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = len(y_test)\n",
    "mismatches = list()\n",
    "\n",
    "for idx, k1 in enumerate(y_test[:size]):\n",
    "    k2 = predicted_labels[idx]\n",
    "\n",
    "    if k1 != k2:\n",
    "        mismatches.append(k1)\n",
    "        \n",
    "        # zoom in to specific errors. Use the index in the next step\n",
    "        if k1 in ('address'):\n",
    "            print(f'[{idx}] expected \"{k1}\" but predicted \"{k2}\"')\n",
    "        \n",
    "f1 = f1_score(y_test[:size], predicted_labels[:size], average=\"weighted\")\n",
    "print(f'Total mismatches: {len(mismatches)} (F1 score: {f1})')\n",
    "\n",
    "data = Counter(mismatches)\n",
    "data.most_common()   # Returns all unique items and their counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = pd.read_parquet('../data/data/raw/test_values.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted \"symbol\", actual label \"symbol\". Actual values:\n",
      "[['VASC', 'TNK', 'NAT', 'GPRO', 'MANH']]\n"
     ]
    }
   ],
   "source": [
    "idx = 57\n",
    "\n",
    "\n",
    "original = test_samples.iloc[idx]\n",
    "converted = original.apply(literal_eval).to_list()\n",
    "\n",
    "print(f'Predicted \"{predicted_labels[idx]}\", actual label \"{y_test[idx]}\". Actual values:\\n{converted}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "dbbef01d25d9fb4d9430fa9d81ea780e18a1c669119e240c1440cbb3ef3d3f19"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
