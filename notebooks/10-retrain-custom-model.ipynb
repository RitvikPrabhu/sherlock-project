{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook enables training and testing of Sherlock.\n",
    "The procedure is:\n",
    "- Load train, val, test datasets (should be preprocessed)\n",
    "- Initialize model using the \"pretrained\" model or by training one from scratch.\n",
    "- Evaluate and analyse the model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTHONHASHSEED=13\n"
     ]
    }
   ],
   "source": [
    "%env PYTHONHASHSEED=13\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will be the ID for the retrained model,\n",
    "#further down predictions can also be made with the original model: \"sherlock\"\n",
    "model_id = 'retrained_sherlock'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "from sherlock.deploy.model import SherlockModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets for training, validation, testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2022-10-15 15:57:04.319767\n",
      "Load data (train) process took 0:00:02.167139 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "print(f'Started at {start}')\n",
    "\n",
    "X_train = pd.read_parquet('../data/data/processed/train.parquet')\n",
    "y_train = pd.read_parquet('../data/data/raw/train_labels.parquet').values.flatten()\n",
    "\n",
    "y_train = np.array([x.lower() for x in y_train])\n",
    "\n",
    "print(f'Load data (train) process took {datetime.now() - start} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct types for columns in the Dataframe (should be all float32):\n",
      "{dtype('float32')}\n"
     ]
    }
   ],
   "source": [
    "print('Distinct types for columns in the Dataframe (should be all float32):')\n",
    "print(set(X_train.dtypes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2022-10-15 15:57:08.896525\n",
      "Load data (validation) process took 0:00:02.014184 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "print(f'Started at {start}')\n",
    "\n",
    "X_validation = pd.read_parquet('../data/data/processed/validation.parquet')\n",
    "y_validation = pd.read_parquet('../data/data/raw/val_labels.parquet').values.flatten()\n",
    "\n",
    "y_validation = np.array([x.lower() for x in y_validation])\n",
    "\n",
    "print(f'Load data (validation) process took {datetime.now() - start} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2022-10-15 15:57:11.250738\n",
      "Finished at 2022-10-15 15:57:12.798950, took 0:00:01.548226 seconds\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "print(f'Started at {start}')\n",
    "\n",
    "X_test = pd.read_parquet('../data/data/processed/test.parquet')\n",
    "y_test = pd.read_parquet('../data/data/raw/test_labels.parquet').values.flatten()\n",
    "\n",
    "y_test = np.array([x.lower() for x in y_test])\n",
    "\n",
    "print(f'Finished at {datetime.now()}, took {datetime.now() - start} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the model\n",
    "Two options:\n",
    "- Load Sherlock model with pretrained weights\n",
    "- Fit Sherlock model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"retrained_sherlock\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2022-10-15 15:57:41.526597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-15 15:57:41.941292: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-15 15:57:41.950972: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "/home/ritvikp/.conda/envs/sherlock/lib/python3.8/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1015 15:57:44.223948 46912496407488 ag_logging.py:142] AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x2aadc85123a0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x2aadc85123a0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  5/254 [..............................] - ETA: 9:20 - loss: 4.1815 - categorical_accuracy: 0.0320"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/ritvikp/CMDA_capstone/sherlock-project/notebooks/10-retrain-custom-model.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btinkercliffs1/home/ritvikp/CMDA_capstone/sherlock-project/notebooks/10-retrain-custom-model.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Btinkercliffs1/home/ritvikp/CMDA_capstone/sherlock-project/notebooks/10-retrain-custom-model.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     model\u001b[39m.\u001b[39;49minitialize_model_from_json(with_weights\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, model_id\u001b[39m=\u001b[39;49mmodel_id);\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btinkercliffs1/home/ritvikp/CMDA_capstone/sherlock-project/notebooks/10-retrain-custom-model.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n",
      "File \u001b[0;32m~/CMDA_capstone/sherlock-project/sherlock/deploy/model.py:173\u001b[0m, in \u001b[0;36mSherlockModel.initialize_model_from_json\u001b[0;34m(self, with_weights, model_id)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(model_filename):\n\u001b[0;32m--> 173\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    174\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m    175\u001b[0m \u001b[39m        No model file associated with this ID: \u001b[39m\u001b[39m{\u001b[39;00mmodel_id\u001b[39m}\u001b[39;00m\u001b[39m, was found.\u001b[39m\n\u001b[1;32m    176\u001b[0m \u001b[39m        The desired model should be specified and stored first before it can be used.\u001b[39m\n\u001b[1;32m    177\u001b[0m \u001b[39m        \u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m    178\u001b[0m     )\n\u001b[1;32m    180\u001b[0m file \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(model_filename, \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: \n                No model file associated with this ID: retrained_sherlock, was found.\n                The desired model should be specified and stored first before it can be used.\n                ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/ritvikp/CMDA_capstone/sherlock-project/notebooks/10-retrain-custom-model.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btinkercliffs1/home/ritvikp/CMDA_capstone/sherlock-project/notebooks/10-retrain-custom-model.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mStarted at \u001b[39m\u001b[39m{\u001b[39;00mstart\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btinkercliffs1/home/ritvikp/CMDA_capstone/sherlock-project/notebooks/10-retrain-custom-model.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Model will be stored with ID `model_id`\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Btinkercliffs1/home/ritvikp/CMDA_capstone/sherlock-project/notebooks/10-retrain-custom-model.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, X_validation, y_validation, model_id\u001b[39m=\u001b[39;49mmodel_id)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btinkercliffs1/home/ritvikp/CMDA_capstone/sherlock-project/notebooks/10-retrain-custom-model.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTrained and saved new model.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btinkercliffs1/home/ritvikp/CMDA_capstone/sherlock-project/notebooks/10-retrain-custom-model.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFinished at \u001b[39m\u001b[39m{\u001b[39;00mdatetime\u001b[39m.\u001b[39mnow()\u001b[39m}\u001b[39;00m\u001b[39m, took \u001b[39m\u001b[39m{\u001b[39;00mdatetime\u001b[39m.\u001b[39mnow() \u001b[39m-\u001b[39m start\u001b[39m}\u001b[39;00m\u001b[39m seconds\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/CMDA_capstone/sherlock-project/sherlock/deploy/model.py:81\u001b[0m, in \u001b[0;36mSherlockModel.fit\u001b[0;34m(self, X_train, y_train, X_val, y_val, model_id)\u001b[0m\n\u001b[1;32m     70\u001b[0m model \u001b[39m=\u001b[39m Model(\n\u001b[1;32m     71\u001b[0m     [char_model_input, word_model_input, par_model_input, rest_model_input],\n\u001b[1;32m     72\u001b[0m     merged_model_output,\n\u001b[1;32m     73\u001b[0m )\n\u001b[1;32m     75\u001b[0m model\u001b[39m.\u001b[39mcompile(\n\u001b[1;32m     76\u001b[0m     optimizer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(lr\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlr),\n\u001b[1;32m     77\u001b[0m     loss\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     78\u001b[0m     metrics\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mcategorical_accuracy\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     79\u001b[0m )\n\u001b[0;32m---> 81\u001b[0m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     82\u001b[0m     [\n\u001b[1;32m     83\u001b[0m         X_train_char\u001b[39m.\u001b[39;49mvalues,\n\u001b[1;32m     84\u001b[0m         X_train_word\u001b[39m.\u001b[39;49mvalues,\n\u001b[1;32m     85\u001b[0m         X_train_par\u001b[39m.\u001b[39;49mvalues,\n\u001b[1;32m     86\u001b[0m         X_train_rest\u001b[39m.\u001b[39;49mvalues,\n\u001b[1;32m     87\u001b[0m     ],\n\u001b[1;32m     88\u001b[0m     y_train_cat,\n\u001b[1;32m     89\u001b[0m     validation_data\u001b[39m=\u001b[39;49m(\n\u001b[1;32m     90\u001b[0m         [\n\u001b[1;32m     91\u001b[0m             X_val_char\u001b[39m.\u001b[39;49mvalues,\n\u001b[1;32m     92\u001b[0m             X_val_word\u001b[39m.\u001b[39;49mvalues,\n\u001b[1;32m     93\u001b[0m             X_val_par\u001b[39m.\u001b[39;49mvalues,\n\u001b[1;32m     94\u001b[0m             X_val_rest\u001b[39m.\u001b[39;49mvalues,\n\u001b[1;32m     95\u001b[0m         ],\n\u001b[1;32m     96\u001b[0m         y_val_cat,\n\u001b[1;32m     97\u001b[0m     ),\n\u001b[1;32m     98\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m     99\u001b[0m     \u001b[39m# epochs=100,\u001b[39;49;00m\n\u001b[1;32m    100\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[1;32m    101\u001b[0m     batch_size\u001b[39m=\u001b[39;49m\u001b[39m256\u001b[39;49m,\n\u001b[1;32m    102\u001b[0m )\n\u001b[1;32m    104\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m model\n\u001b[1;32m    106\u001b[0m _ \u001b[39m=\u001b[39m helpers\u001b[39m.\u001b[39m_get_categorical_label_encodings(y_train, y_val, model_id)\n",
      "File \u001b[0;32m~/.conda/envs/sherlock/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.conda/envs/sherlock/lib/python3.8/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1378\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1379\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1380\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1381\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1382\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1383\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1384\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1385\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1386\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.conda/envs/sherlock/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.conda/envs/sherlock/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.conda/envs/sherlock/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.conda/envs/sherlock/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m   2955\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2957\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/.conda/envs/sherlock/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1849\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1850\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1851\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1852\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1853\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1854\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1855\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m     args,\n\u001b[1;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1858\u001b[0m     executing_eagerly)\n\u001b[1;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.conda/envs/sherlock/lib/python3.8/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/.conda/envs/sherlock/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = SherlockModel()\n",
    "try:\n",
    "    model.initialize_model_from_json(with_weights=True, model_id=model_id);\n",
    "except:\n",
    "    start = datetime.now()\n",
    "    print(f'Started at {start}')\n",
    "    # Model will be stored with ID `model_id`\n",
    "    model.fit(X_train, y_train, X_validation, y_validation, model_id=model_id)\n",
    "\n",
    "    print('Trained and saved new model.')\n",
    "    print(f'Finished at {datetime.now()}, took {datetime.now() - start} seconds')\n",
    "    model.store_weights(model_id=model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0926 03:15:24.883456 46912496407488 ag_logging.py:142] AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x2aadab5b2700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x2aadab5b2700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = model.predict(X_test, model_id)\n",
    "predicted_labels = np.array([x.lower() for x in predicted_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction count 65007, type = <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9131604033035498"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'prediction count {len(predicted_labels)}, type = {type(predicted_labels)}')\n",
    "\n",
    "size=len(y_test)\n",
    "\n",
    "# Should be fully deterministic too.\n",
    "f1_score(y_test[:size], predicted_labels[:size], average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using the original model, model_id should be replaced with \"sherlock\"\n",
    "#model_id = \"sherlock\"\n",
    "classes = np.load(f\"../model_files/classes_{model_id}.npy\", allow_pickle=True)\n",
    "\n",
    "report = classification_report(y_test, predicted_labels, output_dict=True)\n",
    "\n",
    "class_scores = list(filter(lambda x: isinstance(x, tuple) and isinstance(x[1], dict) and 'f1-score' in x[1] and x[0] in classes, list(report.items())))\n",
    "\n",
    "class_scores = sorted(class_scores, key=lambda item: item[1]['f1-score'], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 5 Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tf1-score\tprecision\trecall\t\tsupport\n",
      "industry\t0.986\t\t0.985\t\t0.988\t\t2958\n",
      "birth date\t0.976\t\t0.975\t\t0.977\t\t479\n",
      "currency\t0.971\t\t0.980\t\t0.963\t\t405\n",
      "sex\t\t0.970\t\t0.983\t\t0.958\t\t2997\n",
      "symbol\t\t0.965\t\t0.957\t\t0.972\t\t1752\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\t\\tf1-score\\tprecision\\trecall\\t\\tsupport\")\n",
    "\n",
    "for key, value in class_scores[0:5]:\n",
    "    if len(key) >= 8:\n",
    "        tabs = '\\t' * 1\n",
    "    else:\n",
    "        tabs = '\\t' * 2\n",
    "\n",
    "    print(f\"{key}{tabs}{value['f1-score']:.3f}\\t\\t{value['precision']:.3f}\\t\\t{value['recall']:.3f}\\t\\t{value['support']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bottom 5 Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tf1-score\tprecision\trecall\t\tsupport\n",
      "range\t\t0.778\t\t0.943\t\t0.662\t\t577\n",
      "rank\t\t0.755\t\t0.682\t\t0.847\t\t2983\n",
      "nationality\t0.744\t\t0.665\t\t0.844\t\t424\n",
      "person\t\t0.726\t\t0.876\t\t0.620\t\t579\n",
      "sales\t\t0.408\t\t0.781\t\t0.276\t\t322\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\t\\tf1-score\\tprecision\\trecall\\t\\tsupport\")\n",
    "\n",
    "for key, value in class_scores[len(class_scores)-5:len(class_scores)]:\n",
    "    if len(key) >= 8:\n",
    "        tabs = '\\t' * 1\n",
    "    else:\n",
    "        tabs = '\\t' * 2\n",
    "\n",
    "    print(f\"{key}{tabs}{value['f1-score']:.3f}\\t\\t{value['precision']:.3f}\\t\\t{value['recall']:.3f}\\t\\t{value['support']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     address      0.956     0.966     0.961      3003\n",
      "         age      0.900     0.959     0.929      3033\n",
      "        area      0.950     0.818     0.879      1987\n",
      "  birth date      0.975     0.977     0.976       479\n",
      " birth place      0.990     0.935     0.962       418\n",
      "       brand      0.895     0.772     0.829       574\n",
      "        city      0.892     0.920     0.906      2966\n",
      "   continent      0.787     0.925     0.850       227\n",
      "     country      0.933     0.923     0.928      3038\n",
      "      county      0.938     0.966     0.952      2959\n",
      "    currency      0.980     0.963     0.971       405\n",
      "         day      0.945     0.869     0.905      3038\n",
      "    duration      0.936     0.947     0.941      3000\n",
      "    industry      0.985     0.988     0.986      2958\n",
      "    language      0.862     0.964     0.910      1474\n",
      "    location      0.924     0.845     0.882      2949\n",
      "manufacturer      0.906     0.906     0.906       945\n",
      "        name      0.881     0.906     0.893      3017\n",
      " nationality      0.665     0.844     0.744       424\n",
      "       order      0.836     0.915     0.874      1462\n",
      "      person      0.876     0.620     0.726       579\n",
      "     product      0.918     0.941     0.929      2647\n",
      "       range      0.943     0.662     0.778       577\n",
      "        rank      0.682     0.847     0.755      2983\n",
      "      region      0.935     0.785     0.854      2740\n",
      "       sales      0.781     0.276     0.408       322\n",
      "         sex      0.983     0.958     0.970      2997\n",
      "       state      0.959     0.958     0.959      3030\n",
      "      status      0.948     0.959     0.954      3100\n",
      "      symbol      0.957     0.972     0.965      1752\n",
      "        type      0.896     0.938     0.917      2909\n",
      "        year      0.964     0.959     0.961      3015\n",
      "\n",
      "    accuracy                          0.914     65007\n",
      "   macro avg      0.906     0.881     0.886     65007\n",
      "weighted avg      0.917     0.914     0.913     65007\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predicted_labels, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1187] expected \"address\" but predicted \"location\"\n",
      "[1201] expected \"address\" but predicted \"city\"\n",
      "[1585] expected \"address\" but predicted \"city\"\n",
      "[2256] expected \"address\" but predicted \"person\"\n",
      "[2303] expected \"address\" but predicted \"area\"\n",
      "[2393] expected \"address\" but predicted \"location\"\n",
      "[3342] expected \"address\" but predicted \"city\"\n",
      "[4640] expected \"address\" but predicted \"city\"\n",
      "[4787] expected \"address\" but predicted \"duration\"\n",
      "[5261] expected \"address\" but predicted \"city\"\n",
      "[5729] expected \"address\" but predicted \"location\"\n",
      "[6327] expected \"address\" but predicted \"product\"\n",
      "[7404] expected \"address\" but predicted \"city\"\n",
      "[9532] expected \"address\" but predicted \"manufacturer\"\n",
      "[9920] expected \"address\" but predicted \"language\"\n",
      "[10188] expected \"address\" but predicted \"product\"\n",
      "[11837] expected \"address\" but predicted \"rank\"\n",
      "[12499] expected \"address\" but predicted \"name\"\n",
      "[12829] expected \"address\" but predicted \"name\"\n",
      "[14477] expected \"address\" but predicted \"language\"\n",
      "[15140] expected \"address\" but predicted \"country\"\n",
      "[15145] expected \"address\" but predicted \"language\"\n",
      "[15481] expected \"address\" but predicted \"city\"\n",
      "[16543] expected \"address\" but predicted \"location\"\n",
      "[17047] expected \"address\" but predicted \"language\"\n",
      "[17088] expected \"address\" but predicted \"location\"\n",
      "[17689] expected \"address\" but predicted \"language\"\n",
      "[17747] expected \"address\" but predicted \"county\"\n",
      "[17788] expected \"address\" but predicted \"language\"\n",
      "[18056] expected \"address\" but predicted \"location\"\n",
      "[19063] expected \"address\" but predicted \"language\"\n",
      "[19185] expected \"address\" but predicted \"country\"\n",
      "[19671] expected \"address\" but predicted \"location\"\n",
      "[21290] expected \"address\" but predicted \"area\"\n",
      "[22018] expected \"address\" but predicted \"location\"\n",
      "[22031] expected \"address\" but predicted \"location\"\n",
      "[22419] expected \"address\" but predicted \"language\"\n",
      "[22532] expected \"address\" but predicted \"location\"\n",
      "[22631] expected \"address\" but predicted \"city\"\n",
      "[22678] expected \"address\" but predicted \"type\"\n",
      "[22787] expected \"address\" but predicted \"location\"\n",
      "[23055] expected \"address\" but predicted \"location\"\n",
      "[24818] expected \"address\" but predicted \"location\"\n",
      "[25753] expected \"address\" but predicted \"location\"\n",
      "[27344] expected \"address\" but predicted \"location\"\n",
      "[28218] expected \"address\" but predicted \"name\"\n",
      "[28573] expected \"address\" but predicted \"language\"\n",
      "[28663] expected \"address\" but predicted \"year\"\n",
      "[29339] expected \"address\" but predicted \"language\"\n",
      "[29636] expected \"address\" but predicted \"location\"\n",
      "[30714] expected \"address\" but predicted \"name\"\n",
      "[31830] expected \"address\" but predicted \"rank\"\n",
      "[33071] expected \"address\" but predicted \"city\"\n",
      "[33755] expected \"address\" but predicted \"location\"\n",
      "[34929] expected \"address\" but predicted \"duration\"\n",
      "[35994] expected \"address\" but predicted \"language\"\n",
      "[36306] expected \"address\" but predicted \"language\"\n",
      "[36869] expected \"address\" but predicted \"city\"\n",
      "[38239] expected \"address\" but predicted \"name\"\n",
      "[38517] expected \"address\" but predicted \"location\"\n",
      "[39210] expected \"address\" but predicted \"symbol\"\n",
      "[40218] expected \"address\" but predicted \"name\"\n",
      "[40324] expected \"address\" but predicted \"location\"\n",
      "[40391] expected \"address\" but predicted \"brand\"\n",
      "[40584] expected \"address\" but predicted \"language\"\n",
      "[40677] expected \"address\" but predicted \"language\"\n",
      "[40697] expected \"address\" but predicted \"location\"\n",
      "[41137] expected \"address\" but predicted \"rank\"\n",
      "[41181] expected \"address\" but predicted \"brand\"\n",
      "[41350] expected \"address\" but predicted \"product\"\n",
      "[42378] expected \"address\" but predicted \"location\"\n",
      "[42825] expected \"address\" but predicted \"location\"\n",
      "[42880] expected \"address\" but predicted \"city\"\n",
      "[43719] expected \"address\" but predicted \"location\"\n",
      "[43737] expected \"address\" but predicted \"county\"\n",
      "[44269] expected \"address\" but predicted \"country\"\n",
      "[45332] expected \"address\" but predicted \"city\"\n",
      "[45617] expected \"address\" but predicted \"location\"\n",
      "[45745] expected \"address\" but predicted \"product\"\n",
      "[46897] expected \"address\" but predicted \"status\"\n",
      "[46985] expected \"address\" but predicted \"location\"\n",
      "[47727] expected \"address\" but predicted \"symbol\"\n",
      "[48113] expected \"address\" but predicted \"area\"\n",
      "[48192] expected \"address\" but predicted \"name\"\n",
      "[48830] expected \"address\" but predicted \"language\"\n",
      "[51399] expected \"address\" but predicted \"sales\"\n",
      "[51787] expected \"address\" but predicted \"city\"\n",
      "[52603] expected \"address\" but predicted \"name\"\n",
      "[54105] expected \"address\" but predicted \"rank\"\n",
      "[54767] expected \"address\" but predicted \"range\"\n",
      "[55162] expected \"address\" but predicted \"county\"\n",
      "[56111] expected \"address\" but predicted \"language\"\n",
      "[57887] expected \"address\" but predicted \"name\"\n",
      "[57986] expected \"address\" but predicted \"language\"\n",
      "[59662] expected \"address\" but predicted \"person\"\n",
      "[60279] expected \"address\" but predicted \"product\"\n",
      "[60420] expected \"address\" but predicted \"duration\"\n",
      "[61914] expected \"address\" but predicted \"duration\"\n",
      "[62998] expected \"address\" but predicted \"location\"\n",
      "[64711] expected \"address\" but predicted \"sales\"\n",
      "[64859] expected \"address\" but predicted \"location\"\n",
      "[64864] expected \"address\" but predicted \"location\"\n",
      "[64913] expected \"address\" but predicted \"location\"\n",
      "Total mismatches: 5608 (F1 score: 0.9131604033035498)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('region', 588),\n",
       " ('location', 458),\n",
       " ('rank', 456),\n",
       " ('day', 397),\n",
       " ('area', 362),\n",
       " ('name', 284),\n",
       " ('city', 236),\n",
       " ('country', 234),\n",
       " ('sales', 233),\n",
       " ('person', 220),\n",
       " ('range', 195),\n",
       " ('type', 181),\n",
       " ('duration', 160),\n",
       " ('product', 156),\n",
       " ('brand', 131),\n",
       " ('state', 127),\n",
       " ('status', 126),\n",
       " ('sex', 126),\n",
       " ('year', 125),\n",
       " ('order', 124),\n",
       " ('age', 124),\n",
       " ('address', 103),\n",
       " ('county', 100),\n",
       " ('manufacturer', 89),\n",
       " ('nationality', 66),\n",
       " ('language', 53),\n",
       " ('symbol', 49),\n",
       " ('industry', 35),\n",
       " ('birth place', 27),\n",
       " ('continent', 17),\n",
       " ('currency', 15),\n",
       " ('birth date', 11)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = len(y_test)\n",
    "mismatches = list()\n",
    "\n",
    "for idx, k1 in enumerate(y_test[:size]):\n",
    "    k2 = predicted_labels[idx]\n",
    "\n",
    "    if k1 != k2:\n",
    "        mismatches.append(k1)\n",
    "        \n",
    "        # zoom in to specific errors. Use the index in the next step\n",
    "        if k1 in ('address'):\n",
    "            print(f'[{idx}] expected \"{k1}\" but predicted \"{k2}\"')\n",
    "        \n",
    "f1 = f1_score(y_test[:size], predicted_labels[:size], average=\"weighted\")\n",
    "print(f'Total mismatches: {len(mismatches)} (F1 score: {f1})')\n",
    "\n",
    "data = Counter(mismatches)\n",
    "data.most_common()   # Returns all unique items and their counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = pd.read_parquet('../data/data/raw/test_values.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted \"symbol\", actual label \"symbol\". Actual values:\n",
      "[['VASC', 'TNK', 'NAT', 'GPRO', 'MANH']]\n"
     ]
    }
   ],
   "source": [
    "idx = 57\n",
    "\n",
    "\n",
    "original = test_samples.iloc[idx]\n",
    "converted = original.apply(literal_eval).to_list()\n",
    "\n",
    "print(f'Predicted \"{predicted_labels[idx]}\", actual label \"{y_test[idx]}\". Actual values:\\n{converted}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('sherlock')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "dbbef01d25d9fb4d9430fa9d81ea780e18a1c669119e240c1440cbb3ef3d3f19"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
