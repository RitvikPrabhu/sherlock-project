{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import load\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import requests\n",
    "from io import StringIO\n",
    "import pyarrow.parquet as pq\n",
    "from urllib.error import HTTPError\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "acceptable_columns = ['address', 'age', 'area', 'birth Date', 'birth Place', 'brand', 'city', 'continent', 'country', 'county', 'currency', 'day', 'duration', 'industry', 'language', 'location', 'manufacturer', 'name', 'nationality', 'order', 'person', 'product', 'range', 'rank', 'region','sales', 'sex', 'state', 'status', 'symbol', 'type', 'year']\n",
    "acceptable_columns = np.array(acceptable_columns)\n",
    "# np.save(\"classes_sherlock.npy\", acceptable_columns, allow_pickle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main dataframes to add onto existing dataframe\n",
    "new_train = pd.DataFrame(columns = ['type', 'values'])\n",
    "new_test = pd.DataFrame(columns = ['type', 'values'])\n",
    "new_val = pd.DataFrame(columns = ['type', 'values'])\n",
    "\n",
    "# list of urls of csvs\n",
    "urls = ['https://drive.google.com/file/d/1VBEYn2bV9hUg6Vs97StMMR8NudP--v-D/view?usp=sharing', 'https://drive.google.com/file/d/1XoHPXvb_eAH-90jTSj-1sePVzQtIlw-n/view?usp=sharing',\n",
    "       'https://drive.google.com/file/d/1QwjBOKHSYbEqZxDeUfVZVOjkgb_xuaUt/view?usp=sharing', 'https://drive.google.com/file/d/1I4btyUubuYR6sgz2YhfEftNXdJuKaPaN/view?usp=sharing',\n",
    "       'https://drive.google.com/file/d/1X6B-9hRgENR4xAjL1d0m6BmxGZUs6eGF/view?usp=sharing', 'https://drive.google.com/file/d/1DiHNQZUb9icUhkeBvWYyARKYscDPUAyx/view?usp=sharing',\n",
    "       'https://drive.google.com/file/d/1GhY41caqsjYhTVdUaHqyzp6b-bUJSiX9/view?usp=sharing', 'https://drive.google.com/file/d/1ISLN-fra-7rzfar4b8LvM20YF_UNWC52/view?usp=sharing',\n",
    "       'https://drive.google.com/file/d/140MKfvrMnIy-sfNlovGmHShEETBagMBw/view?usp=sharing', 'https://drive.google.com/file/d/1JPdeXZ5h6zM_esbpUwlpVD-hFx7ifVmm/view?usp=sharing', \n",
    "       'https://drive.google.com/file/d/10eD7XzIql6LOVJlW9C7Wzc1DVnECigBw/view?usp=sharing', 'https://drive.google.com/file/d/1IfQ5SAPgdX8R84qvWxAIy-XoMGC4EuNW/view?usp=sharing',\n",
    "       'https://drive.google.com/file/d/1bHYZGXgYP7PYWrNFvpXGJXKJNgZxhyBU/view?usp=sharing']\n",
    "\n",
    "\n",
    "# list of types\n",
    "types = ['naic', 'credit card account numbers', 'credit card account numbers', 'credit card account numbers', 'fips code', 'lei',\n",
    "        'mcc code', 'phone number', 'zip code', 'guuid','guuid','tax_id','social_security']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through all urls\n",
    "for i in range(len(urls)):\n",
    "    url = urls[i]\n",
    "    #check that url is valid\n",
    "    try:\n",
    "        file_id = url.split('/')[-2]\n",
    "        dwn_url='https://drive.google.com/uc?id=' + file_id\n",
    "        #check that data is csv\n",
    "        try:\n",
    "            data = pd.read_csv(dwn_url, sep=\";\", header=None)\n",
    "            t = types[i]\n",
    "            #check that data is single column\n",
    "            if data.shape[1] != 1:\n",
    "                print('Data is not a single column')\n",
    "                continue\n",
    "        except UnicodeDecodeError:\n",
    "            print('Data not in csv format')\n",
    "            continue\n",
    "    except HTTPError:\n",
    "        print('Error: Link '+ url + ' not valid')\n",
    "        continue\n",
    "    \n",
    "    # split 0.8 to training, 0.1 to test, and 0.1 to validation\n",
    "    train_idx = round(len(data)*0.8)\n",
    "    test_idx = round(len(data)*0.15)\n",
    "    train_data = data.iloc[:train_idx]\n",
    "    test_data = data.iloc[train_idx: (train_idx+test_idx)]\n",
    "    val_data = data.iloc[(train_idx+test_idx):]\n",
    "\n",
    "    # splitting into chunks of ~five data points\n",
    "    train_data = train_data.values.tolist()\n",
    "    #split data from list\n",
    "    train_data = list(itertools.chain(*train_data))\n",
    "    splitval = train_idx/5\n",
    "    train_data = [str(i) for i in train_data]\n",
    "    #split into 5 seperate arrays\n",
    "    train_data_split = np.array_split(train_data, splitval)\n",
    "    #gather arrays into dataframe\n",
    "    train_df = pd.Series(train_data_split, name='values').to_frame()\n",
    "    #set train_df['type'] to current type\n",
    "    train_df['type'] = t\n",
    "    #convert all train_df['values'] to string\n",
    "    train_df = train_df.iloc[:,[1,0]]\n",
    "    train_df['values'] = [str(i) for i in train_df['values']]\n",
    "\n",
    "    #repeat above for test_data\n",
    "    splitval = round(test_idx/5)\n",
    "    test_data = test_data.values.tolist()\n",
    "    test_data = list(itertools.chain(*test_data))\n",
    "    test_data = [str(i) for i in test_data]\n",
    "    test_data_split = np.array_split(test_data, splitval)\n",
    "    test_df = pd.Series(test_data_split, name='values').to_frame()\n",
    "    test_df['type'] = t\n",
    "    test_df = test_df.iloc[:,[1,0]]\n",
    "    test_df['values'] = [str(i) for i in test_df['values']]\n",
    "\n",
    "    #repeat above for validation_data\n",
    "    splitval = round(len(val_data)/5)\n",
    "    val_data = val_data.values.tolist()\n",
    "    val_data = list(itertools.chain(*val_data))\n",
    "    val_data = [str(i) for i in val_data]\n",
    "    val_data_split = np.array_split(val_data, splitval)\n",
    "    val_df = pd.Series(val_data_split, name='values').to_frame()\n",
    "    val_df['type'] = t\n",
    "    val_df = val_df.iloc[:,[1,0]] \n",
    "    val_df['values'] = [str(i) for i in val_df['values']]\n",
    "    \n",
    "    #remove warnings for append dataframe\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    # add to main dataframes\n",
    "    new_train = new_train.append(train_df, ignore_index=True)\n",
    "    new_test = new_test.append(test_df, ignore_index=True)\n",
    "    new_val = new_val.append(val_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa9f7ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pull original sherock testing set\n",
    "test_df_values = pq.read_table(source=\"./data/raw/test_values.parquet\").to_pandas()\n",
    "test_df_labels = pq.read_table(source=\"./data/raw/test_labels.parquet\").to_pandas()\n",
    "test_df_full = test_df_labels.merge(test_df_values, left_index=True, right_index=True)\n",
    "test_df_full = test_df_full[test_df_full['type'].isin(acceptable_columns)]\n",
    "# add new testing data\n",
    "test_df_full = test_df_full.append(new_test, ignore_index=True)\n",
    "test_df_values = pd.DataFrame(test_df_full, columns=['values'])\n",
    "test_df_labels = pd.DataFrame(test_df_full, columns=['type'])\n",
    "len(test_df_full.iloc[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86ea7fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201586</th>\n",
       "      <td>zip code</td>\n",
       "      <td>['36003' '36006' '36067' '36066' '36703' '36701']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201587</th>\n",
       "      <td>zip code</td>\n",
       "      <td>['36091' '36051' '36068' '36008' '36022']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201588</th>\n",
       "      <td>zip code</td>\n",
       "      <td>['36749' '36758' '36550' '36551' '36527']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201589</th>\n",
       "      <td>zip code</td>\n",
       "      <td>['36577' '36559' '36536' '36576' '36579']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201590</th>\n",
       "      <td>zip code</td>\n",
       "      <td>['36502' '36578' '36533' '36564' '36561']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210043</th>\n",
       "      <td>zip code</td>\n",
       "      <td>['57106' '57110' '57109' '57055' '57005']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210044</th>\n",
       "      <td>zip code</td>\n",
       "      <td>['57030' '57033' '57104' '57118' '57107']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210045</th>\n",
       "      <td>zip code</td>\n",
       "      <td>['57020' '57105' '57041' '57003' '57048']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210046</th>\n",
       "      <td>zip code</td>\n",
       "      <td>['57186' '57198' '57015' '57103' '57022']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210047</th>\n",
       "      <td>zip code</td>\n",
       "      <td>['57108' '57053' '57018' '57068' '57028']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8462 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            type                                             values\n",
       "201586  zip code  ['36003' '36006' '36067' '36066' '36703' '36701']\n",
       "201587  zip code          ['36091' '36051' '36068' '36008' '36022']\n",
       "201588  zip code          ['36749' '36758' '36550' '36551' '36527']\n",
       "201589  zip code          ['36577' '36559' '36536' '36576' '36579']\n",
       "201590  zip code          ['36502' '36578' '36533' '36564' '36561']\n",
       "...          ...                                                ...\n",
       "210043  zip code          ['57106' '57110' '57109' '57055' '57005']\n",
       "210044  zip code          ['57030' '57033' '57104' '57118' '57107']\n",
       "210045  zip code          ['57020' '57105' '57041' '57003' '57048']\n",
       "210046  zip code          ['57186' '57198' '57015' '57103' '57022']\n",
       "210047  zip code          ['57108' '57053' '57018' '57068' '57028']\n",
       "\n",
       "[8462 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pull original sherock training set\n",
    "train_df_values = pq.read_table(source=\"./data/raw/train_values.parquet\").to_pandas()\n",
    "train_df_labels = pq.read_table(source=\"./data/raw/train_labels.parquet\").to_pandas()\n",
    "train_df_full = train_df_labels.merge(train_df_values, left_index=True, right_index=True)\n",
    "train_df_full = train_df_full[train_df_full['type'].isin(acceptable_columns)]\n",
    "# add new training data\n",
    "train_df_full = train_df_full.append(new_train, ignore_index=True)\n",
    "train_df_values = pd.DataFrame(train_df_full, columns=['values'])\n",
    "train_df_labels = pd.DataFrame(train_df_full, columns=['type'])\n",
    "train_df_full.loc[train_df_full[\"type\"] == \"zip code\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "258ea1c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>county</td>\n",
       "      <td>['Shelby', 'Knox', 'Washington', 'Davidson', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>age</td>\n",
       "      <td>[20.42, 23.17, 24.5, 24.0, 21.92, 28.08, 25.5,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>address</td>\n",
       "      <td>['San Francisco, CA 94102', 'San Francisco, CA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>duration</td>\n",
       "      <td>['Last 7 Games', 'Last 15 Games', 'Last 30 Gam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>industry</td>\n",
       "      <td>['State government (OES designation)', 'Busine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66130</th>\n",
       "      <td>social_security</td>\n",
       "      <td>['213 18 5932' '100-80-6113' '913 29 5822' '80...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66131</th>\n",
       "      <td>social_security</td>\n",
       "      <td>['136-31-8040' '474-96-8926' '486 66 5129' '85...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66132</th>\n",
       "      <td>social_security</td>\n",
       "      <td>['187 69 1909' '518-01-9530' '355-56-0529' '84...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66133</th>\n",
       "      <td>social_security</td>\n",
       "      <td>['807-13-9017' '752-05-3696' '422-85-0475' '29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66134</th>\n",
       "      <td>social_security</td>\n",
       "      <td>['184 48 2887' '991-58-3877' '279 67 3405' '92...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66135 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  type                                             values\n",
       "0               county  ['Shelby', 'Knox', 'Washington', 'Davidson', '...\n",
       "1                  age  [20.42, 23.17, 24.5, 24.0, 21.92, 28.08, 25.5,...\n",
       "2              address  ['San Francisco, CA 94102', 'San Francisco, CA...\n",
       "3             duration  ['Last 7 Games', 'Last 15 Games', 'Last 30 Gam...\n",
       "4             industry  ['State government (OES designation)', 'Busine...\n",
       "...                ...                                                ...\n",
       "66130  social_security  ['213 18 5932' '100-80-6113' '913 29 5822' '80...\n",
       "66131  social_security  ['136-31-8040' '474-96-8926' '486 66 5129' '85...\n",
       "66132  social_security  ['187 69 1909' '518-01-9530' '355-56-0529' '84...\n",
       "66133  social_security  ['807-13-9017' '752-05-3696' '422-85-0475' '29...\n",
       "66134  social_security  ['184 48 2887' '991-58-3877' '279 67 3405' '92...\n",
       "\n",
       "[66135 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pull original sherock validation set\n",
    "val_df_values = pq.read_table(source=\"./data/raw/val_values.parquet\").to_pandas()\n",
    "val_df_labels = pq.read_table(source=\"./data/raw/val_labels.parquet\").to_pandas()\n",
    "val_df_full = val_df_labels.merge(val_df_values, left_index=True, right_index=True)\n",
    "val_df_full = val_df_full[val_df_full['type'].isin(acceptable_columns)]\n",
    "# add new validation data\n",
    "val_df_full = val_df_full.append(new_val, ignore_index=True)\n",
    "val_df_values = pd.DataFrame(val_df_full, columns=['values'])\n",
    "val_df_labels = pd.DataFrame(val_df_full, columns=['type'])\n",
    "val_df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save test,train,and validation labels to data folder\n",
    "test_df_labels.to_parquet(\"./last_data/raw/test_labels.parquet\", engine='fastparquet')\n",
    "test_df_values.to_parquet(\"./last_data/raw/test_values.parquet\", engine='fastparquet')\n",
    "\n",
    "train_df_labels.to_parquet(\"./last_data/raw/train_labels.parquet\", engine='fastparquet')\n",
    "train_df_values.to_parquet(\"./last_data/raw/train_values.parquet\", engine='fastparquet')\n",
    "\n",
    "val_df_labels.to_parquet(\"./last_data/raw/val_labels.parquet\", engine='fastparquet')\n",
    "val_df_values.to_parquet(\"./last_data/raw/val_values.parquet\", engine='fastparquet')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "19d762ffc7d2f958e0963c75da0d959adf181f4ac62524ed3e80179df28269f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
